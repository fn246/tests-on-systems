{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1 True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__ , torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sdr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import scipy,time,numpy\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "\n",
    "def calc_sdr(estimation, origin, mask=None):\n",
    "    \"\"\"\n",
    "    batch-wise SDR caculation for one audio file.\n",
    "    estimation: (batch, nsample)\n",
    "    origin: (batch, nsample)\n",
    "    mask: optional, (batch, nsample), binary\n",
    "    \"\"\"\n",
    "    \n",
    "    if mask is not None:\n",
    "        origin = origin * mask\n",
    "        estimation = estimation * mask\n",
    "    \n",
    "    origin_power = np.sum(origin**2, 1, keepdims=True) + 1e-8  # (batch, 1)\n",
    "    \n",
    "    scale = np.sum(origin*estimation, 1, keepdims=True) / origin_power  # (batch, 1)\n",
    "    \n",
    "    est_true = scale * origin  # (batch, nsample)\n",
    "    est_res = estimation - est_true  # (batch, nsample)\n",
    "    \n",
    "    true_power = np.sum(est_true**2, 1)\n",
    "    res_power = np.sum(est_res**2, 1)\n",
    "    \n",
    "    return 10*np.log10(true_power) - 10*np.log10(res_power)  # (batch, 1)\n",
    "\n",
    "def calc_sdr_torch(estimation, origin, mask=None):\n",
    "    \"\"\"\n",
    "    batch-wise SDR caculation for one audio file on pytorch Variables.\n",
    "    estimation: (batch, nsample)\n",
    "    origin: (batch, nsample)\n",
    "    mask: optional, (batch, nsample), binary\n",
    "    \"\"\"\n",
    "    \n",
    "    if mask is not None:\n",
    "        origin = origin * mask\n",
    "        estimation = estimation * mask\n",
    "    \n",
    "    origin_power = torch.pow(origin, 2).sum(1, keepdim=True) + 1e-8  # (batch, 1)\n",
    "    \n",
    "    scale = torch.sum(origin*estimation, 1, keepdim=True) / origin_power  # (batch, 1)\n",
    "    \n",
    "    est_true = scale * origin  # (batch, nsample)\n",
    "    est_res = estimation - est_true  # (batch, nsample)\n",
    "    \n",
    "    true_power = torch.pow(est_true, 2).sum(1)\n",
    "    res_power = torch.pow(est_res, 2).sum(1)\n",
    "    \n",
    "    return 10*torch.log10(true_power) - 10*torch.log10(res_power)  # (batch, 1)\n",
    "\n",
    "\n",
    "def batch_SDR(estimation, origin, mask=None):\n",
    "    \"\"\"\n",
    "    batch-wise SDR caculation for multiple audio files.\n",
    "    estimation: (batch, nsource, nsample)\n",
    "    origin: (batch, nsource, nsample)\n",
    "    mask: optional, (batch, nsample), binary\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size_est, nsource_est, nsample_est = estimation.shape\n",
    "    batch_size_ori, nsource_ori, nsample_ori = origin.shape\n",
    "    \n",
    "    assert batch_size_est == batch_size_ori, \"Estimation and original sources should have same shape.\"\n",
    "    assert nsource_est == nsource_ori, \"Estimation and original sources should have same shape.\"\n",
    "    assert nsample_est == nsample_ori, \"Estimation and original sources should have same shape.\"\n",
    "    \n",
    "    assert nsource_est < nsample_est, \"Axis 1 should be the number of sources, and axis 2 should be the signal.\"\n",
    "    \n",
    "    batch_size = batch_size_est\n",
    "    nsource = nsource_est\n",
    "    nsample = nsample_est\n",
    "    \n",
    "    # zero mean signals\n",
    "    estimation = estimation - np.mean(estimation, 2, keepdims=True)\n",
    "    origin = origin - np.mean(origin, 2, keepdims=True)\n",
    "    \n",
    "    # possible permutations\n",
    "    perm = list(set(permutations(np.arange(nsource))))\n",
    "    \n",
    "    # pair-wise SDR\n",
    "    SDR = np.zeros((batch_size, nsource, nsource))\n",
    "    for i in range(nsource):\n",
    "        for j in range(nsource):\n",
    "            SDR[:,i,j] = calc_sdr(estimation[:,i], origin[:,j], mask)\n",
    "    \n",
    "    # choose the best permutation\n",
    "    SDR_max = []\n",
    "    for i in range(batch_size):\n",
    "        SDR_perm = []\n",
    "        for permute in perm:\n",
    "            sdr = 0.\n",
    "            for idx in range(len(permute)):\n",
    "                sdr += SDR[i][idx][permute[idx]]\n",
    "            SDR_perm.append(sdr)\n",
    "        SDR_max.append(np.max(SDR_perm) / nsource)\n",
    "    \n",
    "    return np.asarray(SDR_max)\n",
    "\n",
    "\n",
    "def batch_SDR_torch(estimation, origin, mask=None):\n",
    "    \"\"\"\n",
    "    batch-wise SDR caculation for multiple audio files.\n",
    "    estimation: (batch, nsource, nsample)\n",
    "    origin: (batch, nsource, nsample)\n",
    "    mask: optional, (batch, nsample), binary\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size_est, nsource_est, nsample_est = estimation.size()\n",
    "    batch_size_ori, nsource_ori, nsample_ori = origin.size()\n",
    "    \n",
    "    assert batch_size_est == batch_size_ori, \"Estimation and original sources should have same shape.\"\n",
    "    assert nsource_est == nsource_ori, \"Estimation and original sources should have same shape.\"\n",
    "    assert nsample_est == nsample_ori, \"Estimation and original sources should have same shape.\"\n",
    "    \n",
    "    assert nsource_est < nsample_est, \"Axis 1 should be the number of sources, and axis 2 should be the signal.\"\n",
    "    \n",
    "    batch_size = batch_size_est\n",
    "    nsource = nsource_est\n",
    "    nsample = nsample_est\n",
    "    \n",
    "    # zero mean signals\n",
    "    estimation = estimation - torch.mean(estimation, 2, keepdim=True).expand_as(estimation)\n",
    "    origin = origin - torch.mean(origin, 2, keepdim=True).expand_as(estimation)\n",
    "    \n",
    "    # possible permutations\n",
    "    perm = list(set(permutations(np.arange(nsource))))\n",
    "    \n",
    "    # pair-wise SDR\n",
    "    SDR = torch.zeros((batch_size, nsource, nsource)).type(estimation.type())\n",
    "    for i in range(nsource):\n",
    "        for j in range(nsource):\n",
    "            SDR[:,i,j] = calc_sdr_torch(estimation[:,i], origin[:,j], mask)\n",
    "    \n",
    "    # choose the best permutation\n",
    "    SDR_max = []\n",
    "    SDR_perm = []\n",
    "    for permute in perm:\n",
    "        sdr = []\n",
    "        for idx in range(len(permute)):\n",
    "            sdr.append(SDR[:,idx,permute[idx]].view(batch_size,-1))\n",
    "        sdr = torch.sum(torch.cat(sdr, 1), 1)\n",
    "        SDR_perm.append(sdr.view(batch_size, 1))\n",
    "    SDR_perm = torch.cat(SDR_perm, 1)\n",
    "    SDR_max, _ = torch.max(SDR_perm, dim=1)\n",
    "    \n",
    "    return SDR_max / nsource\n",
    "\n",
    "\n",
    "def compute_measures(se,s,j):\n",
    "    Rss=s.transpose().dot(s)\n",
    "    this_s=s[:,j]\n",
    "\n",
    "    a=this_s.transpose().dot(se)/Rss[j,j]\n",
    "    e_true=a*this_s\n",
    "    e_res=se-a*this_s\n",
    "    Sss=np.sum((e_true)**2)\n",
    "    Snn=np.sum((e_res)**2)\n",
    "\n",
    "    SDR=10*np.log10(Sss/Snn)\n",
    "\n",
    "    Rsr= s.transpose().dot(e_res)\n",
    "    b=np.linalg.inv(Rss).dot(Rsr)\n",
    "\n",
    "    e_interf = s.dot(b)\n",
    "    e_artif= e_res-e_interf\n",
    "\n",
    "    SIR=10*np.log10(Sss/np.sum((e_interf)**2))\n",
    "    SAR=10*np.log10(Sss/np.sum((e_artif)**2))\n",
    "    return SDR, SIR, SAR\n",
    "\n",
    "def GetSDR(se,s):\n",
    "    se=se-np.mean(se,axis=0)\n",
    "    s=s-np.mean(s,axis=0)\n",
    "    nsampl,nsrc=se.shape\n",
    "    nsampl2,nsrc2=s.shape\n",
    "    assert(nsrc2==nsrc)\n",
    "    assert(nsampl2==nsampl)\n",
    "\n",
    "    SDR=np.zeros((nsrc,nsrc))\n",
    "    SIR=SDR.copy()\n",
    "    SAR=SDR.copy()\n",
    "\n",
    "    for jest in range(nsrc):\n",
    "        for jtrue in range(nsrc):\n",
    "            SDR[jest,jtrue],SIR[jest,jtrue],SAR[jest,jtrue]=compute_measures(se[:,jest],s,jtrue)\n",
    "\n",
    "\n",
    "    perm=list(itertools.permutations(np.arange(nsrc)))\n",
    "    nperm=len(perm)\n",
    "    meanSIR=np.zeros((nperm,))\n",
    "    for p in range(nperm):\n",
    "        tp=SIR.transpose().reshape(nsrc*nsrc)\n",
    "        idx=np.arange(nsrc)*nsrc+list(perm[p])\n",
    "        meanSIR[p]=np.mean(tp[idx])\n",
    "    popt=np.argmax(meanSIR)\n",
    "    per=list(perm[popt])\n",
    "    idx=np.arange(nsrc)*nsrc+per\n",
    "    SDR=SDR.transpose().reshape(nsrc*nsrc)[idx]\n",
    "    SIR=SIR.transpose().reshape(nsrc*nsrc)[idx]\n",
    "    SAR=SAR.transpose().reshape(nsrc*nsrc)[idx]\n",
    "    return SDR, SIR, SAR, per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class cLN(nn.Module):\n",
    "    def __init__(self, dimension, eps = 1e-8, trainable=True):\n",
    "        super(cLN, self).__init__()\n",
    "        \n",
    "        self.eps = eps\n",
    "        if trainable:\n",
    "            self.gain = nn.Parameter(torch.ones(1, dimension, 1))\n",
    "            self.bias = nn.Parameter(torch.zeros(1, dimension, 1))\n",
    "        else:\n",
    "            self.gain = Variable(torch.ones(1, dimension, 1), requires_grad=False)\n",
    "            self.bias = Variable(torch.zeros(1, dimension, 1), requires_grad=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input size: (Batch, Freq, Time)\n",
    "        # cumulative mean for each time step\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        channel = input.size(1)\n",
    "        time_step = input.size(2)\n",
    "        \n",
    "        step_sum = input.sum(1)  # B, T\n",
    "        step_pow_sum = input.pow(2).sum(1)  # B, T\n",
    "        cum_sum = torch.cumsum(step_sum, dim=1)  # B, T\n",
    "        cum_pow_sum = torch.cumsum(step_pow_sum, dim=1)  # B, T\n",
    "        \n",
    "        entry_cnt = np.arange(channel, channel*(time_step+1), channel)\n",
    "        entry_cnt = torch.from_numpy(entry_cnt).type(input.type())\n",
    "        entry_cnt = entry_cnt.view(1, -1).expand_as(cum_sum)\n",
    "        \n",
    "        cum_mean = cum_sum / entry_cnt  # B, T\n",
    "        cum_var = (cum_pow_sum - 2*cum_mean*cum_sum) / entry_cnt + cum_mean.pow(2)  # B, T\n",
    "        cum_std = (cum_var + self.eps).sqrt()  # B, T\n",
    "        \n",
    "        cum_mean = cum_mean.unsqueeze(1)\n",
    "        cum_std = cum_std.unsqueeze(1)\n",
    "        \n",
    "        x = (input - cum_mean.expand_as(input)) / cum_std.expand_as(input)\n",
    "        return x * self.gain.expand_as(x).type(x.type()) + self.bias.expand_as(x).type(x.type())\n",
    "    \n",
    "def repackage_hidden(h):\n",
    "    \"\"\"\n",
    "    Wraps hidden states in new Variables, to detach them from their history.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "class MultiRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for multiple stacked RNN layers.\n",
    "    \n",
    "    args:\n",
    "        rnn_type: string, select from 'RNN', 'LSTM' and 'GRU'.\n",
    "        input_size: int, dimension of the input feature. The input should have shape \n",
    "                    (batch, seq_len, input_size).\n",
    "        hidden_size: int, dimension of the hidden state. The corresponding output should \n",
    "                    have shape (batch, seq_len, hidden_size).\n",
    "        num_layers: int, number of stacked RNN layers. Default is 1.\n",
    "        bidirectional: bool, whether the RNN layers are bidirectional. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, input_size, hidden_size, dropout=0, num_layers=1, bidirectional=False):\n",
    "        super(MultiRNN, self).__init__()\n",
    "\n",
    "        self.rnn = getattr(nn, rnn_type)(input_size, hidden_size, num_layers, dropout=dropout, \n",
    "                                         batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_direction = int(bidirectional) + 1\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden = self.init_hidden(input.size(0))\n",
    "        self.rnn.flatten_parameters()\n",
    "        return self.rnn(input, hidden)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (Variable(weight.new(self.num_layers*self.num_direction, batch_size, self.hidden_size).zero_()),\n",
    "                    Variable(weight.new(self.num_layers*self.num_direction, batch_size, self.hidden_size).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.num_layers*self.num_direction, batch_size, self.hidden_size).zero_())\n",
    "        \n",
    "        \n",
    "class FCLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for a fully-connected layer.\n",
    "    \n",
    "    args:\n",
    "        input_size: int, dimension of the input feature. The input should have shape \n",
    "                    (batch, input_size).\n",
    "        hidden_size: int, dimension of the output. The corresponding output should \n",
    "                    have shape (batch, hidden_size).\n",
    "        nonlinearity: string, the nonlinearity applied to the transformation. Default is None.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=None):\n",
    "        super(FCLayer, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.FC = nn.Linear(self.input_size, self.hidden_size, bias=bias)\n",
    "        if nonlinearity:\n",
    "            self.nonlinearity = getattr(F, nonlinearity)\n",
    "        else:\n",
    "            self.nonlinearity = None\n",
    "            \n",
    "        self.init_hidden()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.nonlinearity is not None:\n",
    "            return self.nonlinearity(self.FC(input))\n",
    "        else:\n",
    "            return self.FC(input)\n",
    "              \n",
    "    def init_hidden(self):\n",
    "        initrange = 1. / np.sqrt(self.input_size * self.hidden_size)\n",
    "        self.FC.weight.data.uniform_(-initrange, initrange)\n",
    "        if self.bias:\n",
    "            self.FC.bias.data.fill_(0)\n",
    "            \n",
    "            \n",
    "class DepthConv1d(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channel, hidden_channel, kernel, padding, dilation=1, skip=True, causal=False):\n",
    "        super(DepthConv1d, self).__init__()\n",
    "        \n",
    "        self.causal = causal\n",
    "        self.skip = skip\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(input_channel, hidden_channel, 1)\n",
    "        if self.causal:\n",
    "            self.padding = (kernel - 1) * dilation\n",
    "        else:\n",
    "            self.padding = padding\n",
    "        self.dconv1d = nn.Conv1d(hidden_channel, hidden_channel, kernel, dilation=dilation,\n",
    "          groups=hidden_channel,\n",
    "          padding=self.padding)\n",
    "        self.res_out = nn.Conv1d(hidden_channel, input_channel, 1)\n",
    "        self.nonlinearity1 = nn.PReLU()\n",
    "        self.nonlinearity2 = nn.PReLU()\n",
    "        if self.causal:\n",
    "            self.reg1 = cLN(hidden_channel, eps=1e-08)\n",
    "            self.reg2 = cLN(hidden_channel, eps=1e-08)\n",
    "        else:\n",
    "            self.reg1 = nn.GroupNorm(1, hidden_channel, eps=1e-08)\n",
    "            self.reg2 = nn.GroupNorm(1, hidden_channel, eps=1e-08)\n",
    "        \n",
    "        if self.skip:\n",
    "            self.skip_out = nn.Conv1d(hidden_channel, input_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.reg1(self.nonlinearity1(self.conv1d(input)))\n",
    "        if self.causal:\n",
    "            output = self.reg2(self.nonlinearity2(self.dconv1d(output)[:,:,:-self.padding]))\n",
    "        else:\n",
    "            output = self.reg2(self.nonlinearity2(self.dconv1d(output)))\n",
    "        residual = self.res_out(output)\n",
    "        if self.skip:\n",
    "            skip = self.skip_out(output)\n",
    "            return residual, skip\n",
    "        else:\n",
    "            return residual\n",
    "        \n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, BN_dim, hidden_dim,\n",
    "                 layer, stack, kernel=3, skip=True, \n",
    "                 causal=False, dilated=True):\n",
    "        super(TCN, self).__init__()\n",
    "        \n",
    "        # input is a sequence of features of shape (B, N, L)\n",
    "        \n",
    "        # normalization\n",
    "        if not causal:\n",
    "            self.LN = nn.GroupNorm(1, input_dim, eps=1e-8)\n",
    "        else:\n",
    "            self.LN = cLN(input_dim, eps=1e-8)\n",
    "\n",
    "        self.BN = nn.Conv1d(input_dim, BN_dim, 1)\n",
    "        \n",
    "        # TCN for feature extraction\n",
    "        self.receptive_field = 0\n",
    "        self.dilated = dilated\n",
    "        \n",
    "        self.TCN = nn.ModuleList([])\n",
    "        for s in range(stack):\n",
    "            for i in range(layer):\n",
    "                if self.dilated:\n",
    "                    self.TCN.append(DepthConv1d(BN_dim, hidden_dim, kernel, dilation=2**i, padding=2**i, skip=skip, causal=causal)) \n",
    "                else:\n",
    "                    self.TCN.append(DepthConv1d(BN_dim, hidden_dim, kernel, dilation=1, padding=1, skip=skip, causal=causal))   \n",
    "                if i == 0 and s == 0:\n",
    "                    self.receptive_field += kernel\n",
    "                else:\n",
    "                    if self.dilated:\n",
    "                        self.receptive_field += (kernel - 1) * 2**i\n",
    "                    else:\n",
    "                        self.receptive_field += (kernel - 1)\n",
    "                    \n",
    "        #print(\"Receptive field: {:3d} frames.\".format(self.receptive_field))\n",
    "        \n",
    "        # output layer\n",
    "        \n",
    "        self.output = nn.Sequential(nn.PReLU(),\n",
    "                                    nn.Conv1d(BN_dim, output_dim, 1)\n",
    "                                   )\n",
    "        \n",
    "        self.skip = skip\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        # input shape: (B, N, L)\n",
    "        \n",
    "        # normalization\n",
    "        output = self.BN(self.LN(input))\n",
    "        \n",
    "        # pass to TCN\n",
    "        if self.skip:\n",
    "            skip_connection = 0.\n",
    "            for i in range(len(self.TCN)):\n",
    "                residual, skip = self.TCN[i](output)\n",
    "                output = output + residual\n",
    "                skip_connection = skip_connection + skip\n",
    "        else:\n",
    "            for i in range(len(self.TCN)):\n",
    "                residual = self.TCN[i](output)\n",
    "                output = output + residual\n",
    "            \n",
    "        # output layer\n",
    "        if self.skip:\n",
    "            output = self.output(skip_connection)\n",
    "        else:\n",
    "            output = self.output(output)\n",
    "        \n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv_tasnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#from .utility import models, sdr\n",
    "\n",
    "\n",
    "# Conv-TasNet\n",
    "class TasNet(nn.Module):\n",
    "    def __init__(self, enc_dim=512, feature_dim=128, sr=16000, win=2, layer=8, stack=3, \n",
    "                 kernel=3, num_spk=2, causal=False):\n",
    "        super(TasNet, self).__init__()\n",
    "        \n",
    "        # hyper parameters\n",
    "        self.num_spk = num_spk\n",
    "\n",
    "        self.enc_dim = enc_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.win = int(sr*win/1000)\n",
    "        self.stride = self.win // 2\n",
    "        \n",
    "        self.layer = layer\n",
    "        self.stack = stack\n",
    "        self.kernel = kernel\n",
    "\n",
    "        self.causal = causal\n",
    "        \n",
    "        # input encoder\n",
    "        self.encoder = nn.Conv1d(1, self.enc_dim, self.win, bias=False, stride=self.stride)\n",
    "        \n",
    "        # TCN separator\n",
    "       #fatemeh: self.TCN = models.TCN(self.enc_dim, self.enc_dim*self.num_spk, self.feature_dim, self.feature_dim*4,\n",
    "        #                      self.layer, self.stack, self.kernel, causal=self.causal)\n",
    "        self.TCN = TCN(self.enc_dim, self.enc_dim*self.num_spk, self.feature_dim, self.feature_dim*4,\n",
    "                              self.layer, self.stack, self.kernel, causal=self.causal)\n",
    "        self.receptive_field = self.TCN.receptive_field\n",
    "        \n",
    "        # output decoder\n",
    "        self.decoder = nn.ConvTranspose1d(self.enc_dim, 1, self.win, bias=False, stride=self.stride)\n",
    "\n",
    "    def pad_signal(self, input):\n",
    "\n",
    "        # input is the waveforms: (B, T) or (B, 1, T)\n",
    "        # reshape and padding\n",
    "        if input.dim() not in [2, 3]:\n",
    "            raise RuntimeError(\"Input can only be 2 or 3 dimensional.\")\n",
    "        \n",
    "        if input.dim() == 2:\n",
    "            input = input.unsqueeze(1)\n",
    "        batch_size = input.size(0)\n",
    "        nsample = input.size(2)\n",
    "        rest = self.win - (self.stride + nsample % self.win) % self.win\n",
    "        if rest > 0:\n",
    "            pad = Variable(torch.zeros(batch_size, 1, rest)).type(input.type())\n",
    "            input = torch.cat([input, pad], 2)\n",
    "        \n",
    "        pad_aux = Variable(torch.zeros(batch_size, 1, self.stride)).type(input.type())\n",
    "        input = torch.cat([pad_aux, input, pad_aux], 2)\n",
    "\n",
    "        return input, rest\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        # padding\n",
    "        output, rest = self.pad_signal(input)\n",
    "        batch_size = output.size(0)\n",
    "        \n",
    "        # waveform encoder\n",
    "        enc_output = self.encoder(output)  # B, N, L\n",
    "\n",
    "        # generate masks\n",
    "        masks = torch.sigmoid(self.TCN(enc_output)).view(batch_size, self.num_spk, self.enc_dim, -1)  # B, C, N, L\n",
    "        masked_output = enc_output.unsqueeze(1) * masks  # B, C, N, L\n",
    "        \n",
    "        # waveform decoder\n",
    "        output = self.decoder(masked_output.view(batch_size*self.num_spk, self.enc_dim, -1))  # B*C, 1, L\n",
    "        output = output[:,:,self.stride:-(rest+self.stride)].contiguous()  # B*C, 1, L\n",
    "        output = output.view(batch_size, self.num_spk, -1)  # B, C, T\n",
    "        \n",
    "        return output\n",
    "\n",
    "#def test_conv_tasnet():\n",
    "    #x = torch.rand(2, 32000)\n",
    "    #nnet = TasNet()\n",
    "    #x = nnet(x)\n",
    "    #s1 = x[0]\n",
    "    #print(s1.shape)\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#test_conv_tasnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 32000)\n",
    "\n",
    "nnet = TasNet()\n",
    "y = nnet(x)\n",
    "s1 = y[0]\n",
    "print(s1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 32000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=[]\n",
    "ss=[]\n",
    "#xx=torch.empty(10,2,32000)\n",
    "for i in range(10):\n",
    "    x = torch.rand(1, 32000)\n",
    "    y = torch.rand(1,32000)\n",
    "    z=x+y\n",
    "    s=torch.rand(1,32000)\n",
    "    zz.append(z)\n",
    "    ss.append(s)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TasNet(\n",
       "  (encoder): Conv1d(1, 512, kernel_size=(32,), stride=(16,), bias=False)\n",
       "  (TCN): TCN(\n",
       "    (LN): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "    (BN): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    (TCN): ModuleList(\n",
       "      (0): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (9): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (10): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (11): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (12): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (13): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (14): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (15): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (16): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (17): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (18): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (19): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (20): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (21): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (22): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (23): DepthConv1d(\n",
       "        (conv1d): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (dconv1d): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (nonlinearity1): PReLU(num_parameters=1)\n",
       "        (nonlinearity2): PReLU(num_parameters=1)\n",
       "        (reg1): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (reg2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (0): PReLU(num_parameters=1)\n",
       "      (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvTranspose1d(512, 1, kernel_size=(32,), stride=(16,), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=TasNet()\n",
    "#model=model.to('cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx=torch.tensor(xx[0])\n",
    "xxx.size()\n",
    "ymix=\n",
    "ysource="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset,Dataset\n",
    "train=TensorDataset(Tensor(),Tensor())\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss & optimizer\n",
    "learning_rate=1e-3\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YESSSS!\n",
      "Epoch [1/5] , Loss60.8708\n",
      "YESSSS!\n",
      "Epoch [2/5] , Loss45.4144\n",
      "YESSSS!\n",
      "Epoch [3/5] , Loss46.5550\n",
      "YESSSS!\n",
      "Epoch [4/5] , Loss48.9051\n",
      "YESSSS!\n",
      "Epoch [5/5] , Loss45.7532\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "c=torch.tensor(s1)\n",
    "LOSS=[]\n",
    "num_epoch=5\n",
    "total_step=20\n",
    "for epoch in range(num_epoch):\n",
    "    for batch_x in train_loader:\n",
    "        a=torch.tensor(batch_x[0])\n",
    "        #batch_x=torch.tensor(batch_x)\n",
    "        b=a\n",
    "        #b=a.to('cuda')\n",
    "        outputs=model(b)\n",
    "        loss=criterion(outputs,c)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "       \n",
    "        optimizer.step()\n",
    "        LOSS.append(loss.item())\n",
    "        print('Epoch [{}/{}] , Loss{:.4f}'\n",
    "             .format(epoch+1,num_epoch ,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.7104e-01, 1.4285e-01, 2.4516e-02,  ..., 6.3580e-01, 1.7851e-01,\n",
      "         1.6638e-01],\n",
      "        [5.5505e-01, 3.3999e-01, 4.5126e-01,  ..., 3.1689e-01, 9.8371e-01,\n",
      "         7.8938e-01]])\n"
     ]
    }
   ],
   "source": [
    "for batch_x in train_loader:\n",
    "    a=torch.tensor(batch_x[0])\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4cf0a64f61c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torchaudio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_mod_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from torchaudio import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mcompliance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torchaudio/extension/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_init_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torchaudio/extension/extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'torchaudio._torchaudio'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_mod_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_module_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_init_script_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torchaudio C++ extension is not available.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torchaudio/extension/extension.py\u001b[0m in \u001b[0;36m_init_script_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_init_script_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'classes'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f_torch",
   "language": "python",
   "name": "f_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
