{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==0.4.1 in /home/speech/f_torch/lib/python3.6/site-packages (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in /home/speech/f_torch/lib/python3.6/site-packages (0.6.0)\n",
      "Collecting torch==1.6.0\n",
      "  Using cached torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8 MB)\n",
      "Requirement already satisfied: numpy in /home/speech/f_torch/lib/python3.6/site-packages (from torch==1.6.0->torchaudio) (1.19.1)\n",
      "Requirement already satisfied: future in /home/speech/f_torch/lib/python3.6/site-packages (from torch==1.6.0->torchaudio) (0.18.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 0.4.1\n",
      "    Uninstalling torch-0.4.1:\n",
      "      Successfully uninstalled torch-0.4.1\n",
      "Successfully installed torch-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import torchaudio\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "#print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 23 22:27:47 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 415.18       Driver Version: 415.18       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   50C    P2    37W / 180W |    955MiB /  8116MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      2019      G   /usr/lib/xorg/Xorg                            18MiB |\r\n",
      "|    0      2074      G   /usr/bin/gnome-shell                          48MiB |\r\n",
      "|    0      2306      G   /usr/lib/xorg/Xorg                           118MiB |\r\n",
      "|    0      2437      G   /usr/bin/gnome-shell                         155MiB |\r\n",
      "|    0      5043      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files   102MiB |\r\n",
      "|    0      8618      C   /home/speech/f_torch/bin/python              507MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import torchaudio\n",
    "print(torch.__version__)\n",
    "#print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2., 4., 2., 0.],\n",
      "          [0., 2., 1., 2.],\n",
      "          [4., 4., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 2., 4.],\n",
      "          [4., 1., 3., 0.],\n",
      "          [0., 1., 0., 2.]]],\n",
      "\n",
      "\n",
      "        [[[4., 2., 1., 1.],\n",
      "          [0., 1., 1., 0.],\n",
      "          [3., 4., 4., 1.]],\n",
      "\n",
      "         [[1., 3., 0., 0.],\n",
      "          [4., 1., 1., 2.],\n",
      "          [3., 1., 2., 2.]]]])\n",
      "tensor([[[2., 4., 2., 2., 5., 6., 1., 1.],\n",
      "         [1., 1., 6., 5., 3., 1., 0., 2.]],\n",
      "\n",
      "        [[4., 2., 1., 2., 4., 4., 4., 1.],\n",
      "         [1., 3., 4., 1., 4., 3., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "# Created on 2018/12\n",
    "# Author: Kaituo XU\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def overlap_and_add(signal, frame_step):\n",
    "    \"\"\"Reconstructs a signal from a framed representation.\n",
    "\n",
    "    Adds potentially overlapping frames of a signal with shape\n",
    "    `[..., frames, frame_length]`, offsetting subsequent frames by `frame_step`.\n",
    "    The resulting tensor has shape `[..., output_size]` where\n",
    "\n",
    "        output_size = (frames - 1) * frame_step + frame_length\n",
    "\n",
    "    Args:\n",
    "        signal: A [..., frames, frame_length] Tensor. All dimensions may be unknown, and rank must be at least 2.\n",
    "        frame_step: An integer denoting overlap offsets. Must be less than or equal to frame_length.\n",
    "\n",
    "    Returns:\n",
    "        A Tensor with shape [..., output_size] containing the overlap-added frames of signal's inner-most two dimensions.\n",
    "        output_size = (frames - 1) * frame_step + frame_length\n",
    "\n",
    "    Based on https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/contrib/signal/python/ops/reconstruction_ops.py\n",
    "    \"\"\"\n",
    "    outer_dimensions = signal.size()[:-2]\n",
    "    frames, frame_length = signal.size()[-2:]\n",
    "\n",
    "    subframe_length = math.gcd(frame_length, frame_step)  # gcd=Greatest Common Divisor\n",
    "    subframe_step = frame_step // subframe_length\n",
    "    subframes_per_frame = frame_length // subframe_length\n",
    "    output_size = frame_step * (frames - 1) + frame_length\n",
    "    output_subframes = output_size // subframe_length\n",
    "\n",
    "    subframe_signal = signal.view(*outer_dimensions, -1, subframe_length)\n",
    "\n",
    "    frame = torch.arange(0, output_subframes).unfold(0, subframes_per_frame, subframe_step)\n",
    "    frame = signal.new_tensor(frame).long()  # signal may in GPU or CPU\n",
    "    frame = frame.contiguous().view(-1)\n",
    "\n",
    "    result = signal.new_zeros(*outer_dimensions, output_subframes, subframe_length)\n",
    "    result.index_add_(-2, frame, subframe_signal)\n",
    "    result = result.view(*outer_dimensions, -1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_pad(inputs, inputs_lengths):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: torch.Tensor, [B, C, T] or [B, T], B is batch size\n",
    "        inputs_lengths: torch.Tensor, [B]\n",
    "    Returns:\n",
    "        results: a list containing B items, each item is [C, T], T varies\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    dim = inputs.dim()\n",
    "    if dim == 3:\n",
    "        C = inputs.size(1)\n",
    "    for input, length in zip(inputs, inputs_lengths):\n",
    "        if dim == 3: # [B, C, T]\n",
    "            results.append(input[:,:length].view(C, -1).cpu().numpy())\n",
    "        elif dim == 2:  # [B, T]\n",
    "            results.append(input[:length].view(-1).cpu().numpy())\n",
    "    return results\n",
    "\n",
    "#%%\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(123)\n",
    "    M, C, K, N = 2, 2, 3, 4\n",
    "    frame_step = 2\n",
    "    signal = torch.randint(5, (M, C, K, N))\n",
    "    result = overlap_and_add(signal, frame_step)\n",
    "    print(signal)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv_tasnet.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixture tensor([[1., 1., 0., 0., 1., 2., 0., 2., 2., 1., 2., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "U Parameter containing:\n",
      "tensor([[[1., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 0., 1.]],\n",
      "\n",
      "        [[1., 1., 0., 0.]]], requires_grad=True)\n",
      "mixture_w tensor([[[1., 2., 3., 1., 3.],\n",
      "         [1., 2., 4., 3., 2.],\n",
      "         [2., 0., 3., 2., 3.]],\n",
      "\n",
      "        [[0., 1., 1., 2., 1.],\n",
      "         [1., 0., 1., 2., 1.],\n",
      "         [1., 1., 0., 2., 2.]]], grad_fn=<ReluBackward>)\n",
      "mixture_w size torch.Size([2, 3, 5])\n",
      "est_mask tensor([[[[0.1345, 0.0000, 0.0000, 0.0486, 0.0000],\n",
      "          [0.0000, 0.0000, 0.4120, 0.0000, 0.0099],\n",
      "          [1.2053, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.3484, 0.0000, 0.0000, 0.5841, 0.0000],\n",
      "          [0.0000, 0.0000, 0.4588, 0.0000, 0.0332],\n",
      "          [0.9679, 0.0000, 0.0150, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0245, 0.1034, 0.0254, 0.0332, 0.0556],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.8334, 0.0422, 0.0000, 0.7139]],\n",
      "\n",
      "         [[0.3503, 1.0517, 0.2848, 0.3830, 0.5215],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5742, 0.0000, 0.0000, 0.7939]]]], grad_fn=<ReluBackward>)\n",
      "est_source tensor([[[-1.0498, -0.9447, -0.3215, -0.4871,  0.7658,  0.3028,  0.2324,\n",
      "           0.2837,  0.0331,  0.0055,  0.0027,  0.0036],\n",
      "         [-0.5729, -1.0902,  0.3502, -0.3446,  0.8327,  0.3202,  0.3671,\n",
      "           0.1650,  0.3174,  0.0341,  0.0089,  0.0120]],\n",
      "\n",
      "        [[ 0.0000,  0.0000, -0.3505, -0.3418, -0.0777, -0.1731,  0.0269,\n",
      "          -0.0168, -0.5944, -0.5506, -0.2022, -0.2894],\n",
      "         [ 0.0000,  0.0000, -0.0280, -0.4976,  0.4856, -0.1539,  0.3065,\n",
      "          -0.1941, -0.2215, -0.7093,  0.0006, -0.3046]]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "est_source tensor([[[ 0.0000,  0.0000,  0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<ConstantPadNdBackward>)\n",
      "est_source size torch.Size([2, 2, 29495])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Created on 2018/12\n",
    "# Author: Kaituo XU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import overlap_and_add\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "\n",
    "class ConvTasNet(nn.Module):\n",
    "    def __init__(self, N, L, B, H, P, X, R, C, norm_type=\"gLN\", causal=False,\n",
    "                 mask_nonlinear='relu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            N: Number of filters in autoencoder\n",
    "            L: Length of the filters (in samples)\n",
    "            B: Number of channels in bottleneck 1 × 1-conv block\n",
    "            H: Number of channels in convolutional blocks\n",
    "            P: Kernel size in convolutional blocks\n",
    "            X: Number of convolutional blocks in each repeat\n",
    "            R: Number of repeats\n",
    "            C: Number of speakers\n",
    "            norm_type: BN, gLN, cLN\n",
    "            causal: causal or non-causal\n",
    "            mask_nonlinear: use which non-linear function to generate mask\n",
    "        \"\"\"\n",
    "        super(ConvTasNet, self).__init__()\n",
    "        # Hyper-parameter\n",
    "        self.N, self.L, self.B, self.H, self.P, self.X, self.R, self.C = N, L, B, H, P, X, R, C\n",
    "        self.norm_type = norm_type\n",
    "        self.causal = causal\n",
    "        self.mask_nonlinear = mask_nonlinear\n",
    "        # Components\n",
    "        self.encoder = Encoder(L, N)\n",
    "        self.separator = TemporalConvNet(N, B, H, P, X, R, C, norm_type, causal, mask_nonlinear)\n",
    "        self.decoder = Decoder(N, L)\n",
    "        # init\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_normal_(p)\n",
    "\n",
    "    def forward(self, mixture):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mixture: [M, T], M is batch size, T is #samples\n",
    "        Returns:\n",
    "            est_source: [M, C, T]\n",
    "        \"\"\"\n",
    "        mixture_w = self.encoder(mixture)\n",
    "        est_mask = self.separator(mixture_w)\n",
    "        est_source = self.decoder(mixture_w, est_mask)\n",
    "\n",
    "        # T changed after conv1d in encoder, fix it here\n",
    "        T_origin = mixture.size(-1)\n",
    "        T_conv = est_source.size(-1)\n",
    "        est_source = F.pad(est_source, (0, T_origin - T_conv))\n",
    "        return est_source\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, path):\n",
    "        # Load to CPU\n",
    "        package = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        model = cls.load_model_from_package(package)\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def load_model_from_package(cls, package):\n",
    "        model = cls(package['N'], package['L'], package['B'], package['H'],\n",
    "                    package['P'], package['X'], package['R'], package['C'],\n",
    "                    norm_type=package['norm_type'], causal=package['causal'],\n",
    "                    mask_nonlinear=package['mask_nonlinear'])\n",
    "        model.load_state_dict(package['state_dict'])\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def serialize(model, optimizer, epoch, tr_loss=None, cv_loss=None):\n",
    "        package = {\n",
    "            # hyper-parameter\n",
    "            'N': model.N, 'L': model.L, 'B': model.B, 'H': model.H,\n",
    "            'P': model.P, 'X': model.X, 'R': model.R, 'C': model.C,\n",
    "            'norm_type': model.norm_type, 'causal': model.causal,\n",
    "            'mask_nonlinear': model.mask_nonlinear,\n",
    "            # state\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optim_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        if tr_loss is not None:\n",
    "            package['tr_loss'] = tr_loss\n",
    "            package['cv_loss'] = cv_loss\n",
    "        return package\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Estimation of the nonnegative mixture weight by a 1-D conv layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, L, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Hyper-parameter\n",
    "        self.L, self.N = L, N\n",
    "        # Components\n",
    "        # 50% overlap\n",
    "        self.conv1d_U = nn.Conv1d(1, N, kernel_size=L, stride=L // 2, bias=False)\n",
    "\n",
    "    def forward(self, mixture):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mixture: [M, T], M is batch size, T is #samples\n",
    "        Returns:\n",
    "            mixture_w: [M, N, K], where K = (T-L)/(L/2)+1 = 2T/L-1\n",
    "        \"\"\"\n",
    "        mixture = torch.unsqueeze(mixture, 1)  # [M, 1, T]\n",
    "        mixture_w = F.relu(self.conv1d_U(mixture))  # [M, N, K]\n",
    "        return mixture_w\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, N, L):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Hyper-parameter\n",
    "        self.N, self.L = N, L\n",
    "        # Components\n",
    "        self.basis_signals = nn.Linear(N, L, bias=False)\n",
    "\n",
    "    def forward(self, mixture_w, est_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mixture_w: [M, N, K]\n",
    "            est_mask: [M, C, N, K]\n",
    "        Returns:\n",
    "            est_source: [M, C, T]\n",
    "        \"\"\"\n",
    "        # D = W * M\n",
    "        #fatemeh: size(torch.unsqueeze()):torch.Size([2, 1, 3, 5]) , size(est_mask):torch.Size([2, 5, 2, 3])\n",
    "        source_w = torch.unsqueeze(mixture_w, 1) * est_mask  # [M, C, N, K]\n",
    "        source_w = torch.transpose(source_w, 2, 3) # [M, C, K, N]\n",
    "        # S = DV\n",
    "        est_source = self.basis_signals(source_w)  # [M, C, K, L]\n",
    "        est_source = overlap_and_add(est_source, self.L//2) # M x C x T\n",
    "        return est_source\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, N, B, H, P, X, R, C, norm_type=\"gLN\", causal=False,\n",
    "                 mask_nonlinear='relu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            N: Number of filters in autoencoder\n",
    "            B: Number of channels in bottleneck 1 × 1-conv block\n",
    "            H: Number of channels in convolutional blocks\n",
    "            P: Kernel size in convolutional blocks\n",
    "            X: Number of convolutional blocks in each repeat\n",
    "            R: Number of repeats\n",
    "            C: Number of speakers\n",
    "            norm_type: BN, gLN, cLN\n",
    "            causal: causal or non-causal\n",
    "            mask_nonlinear: use which non-linear function to generate mask\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        # Hyper-parameter\n",
    "        self.C = C\n",
    "        self.mask_nonlinear = mask_nonlinear\n",
    "        # Components\n",
    "        # [M, N, K] -> [M, N, K]\n",
    "        layer_norm = ChannelwiseLayerNorm(N)\n",
    "        # [M, N, K] -> [M, B, K]\n",
    "        bottleneck_conv1x1 = nn.Conv1d(N, B, 1, bias=False)\n",
    "        # [M, B, K] -> [M, B, K]\n",
    "        repeats = []\n",
    "        for r in range(R):\n",
    "            blocks = []\n",
    "            for x in range(X):\n",
    "                dilation = 2**x\n",
    "                padding = (P - 1) * dilation if causal else (P - 1) * dilation // 2\n",
    "                blocks += [TemporalBlock(B, H, P, stride=1,\n",
    "                                         padding=padding,\n",
    "                                         dilation=dilation,\n",
    "                                         norm_type=norm_type,\n",
    "                                         causal=causal)]\n",
    "            repeats += [nn.Sequential(*blocks)]\n",
    "        temporal_conv_net = nn.Sequential(*repeats)\n",
    "        # [M, B, K] -> [M, C*N, K]\n",
    "        mask_conv1x1 = nn.Conv1d(B, C*N, 1, bias=False)\n",
    "        # Put together\n",
    "        self.network = nn.Sequential(layer_norm,\n",
    "                                     bottleneck_conv1x1,\n",
    "                                     temporal_conv_net,\n",
    "                                     mask_conv1x1)\n",
    "\n",
    "    def forward(self, mixture_w):\n",
    "        \"\"\"\n",
    "        Keep this API same with TasNet\n",
    "        Args:\n",
    "            mixture_w: [M, N, K], M is batch size\n",
    "        returns:\n",
    "            est_mask: [M, C, N, K]\n",
    "        \"\"\"\n",
    "        M, N, K = mixture_w.size()\n",
    "        score = self.network(mixture_w)  # [M, N, K] -> [M, C*N, K]\n",
    "        score = score.view(M, self.C, N, K) # [M, C*N, K] -> [M, C, N, K]\n",
    "        if self.mask_nonlinear == 'softmax':\n",
    "            est_mask = F.softmax(score, dim=1)\n",
    "        elif self.mask_nonlinear == 'relu':\n",
    "            est_mask = F.relu(score)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported mask non-linear function\")\n",
    "        return est_mask\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride, padding, dilation, norm_type=\"gLN\", causal=False):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # [M, B, K] -> [M, H, K]\n",
    "        conv1x1 = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n",
    "        prelu = nn.PReLU()\n",
    "        norm = chose_norm(norm_type, out_channels)\n",
    "        # [M, H, K] -> [M, B, K]\n",
    "        dsconv = DepthwiseSeparableConv(out_channels, in_channels, kernel_size,\n",
    "                                        stride, padding, dilation, norm_type,\n",
    "                                        causal)\n",
    "        # Put together\n",
    "        self.net = nn.Sequential(conv1x1, prelu, norm, dsconv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [M, B, K]\n",
    "        Returns:\n",
    "            [M, B, K]\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.net(x)\n",
    "        # TODO: when P = 3 here works fine, but when P = 2 maybe need to pad?\n",
    "        return out + residual  # look like w/o F.relu is better than w/ F.relu\n",
    "        # return F.relu(out + residual)\n",
    "\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride, padding, dilation, norm_type=\"gLN\", causal=False):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        # Use `groups` option to implement depthwise convolution\n",
    "        # [M, H, K] -> [M, H, K]\n",
    "        depthwise_conv = nn.Conv1d(in_channels, in_channels, kernel_size,\n",
    "                                   stride=stride, padding=padding,\n",
    "                                   dilation=dilation, groups=in_channels,\n",
    "                                   bias=False)\n",
    "        if causal:\n",
    "            chomp = Chomp1d(padding)\n",
    "        prelu = nn.PReLU()\n",
    "        norm = chose_norm(norm_type, in_channels)\n",
    "        # [M, H, K] -> [M, B, K]\n",
    "        pointwise_conv = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n",
    "        # Put together\n",
    "        if causal:\n",
    "            self.net = nn.Sequential(depthwise_conv, chomp, prelu, norm,\n",
    "                                     pointwise_conv)\n",
    "        else:\n",
    "            self.net = nn.Sequential(depthwise_conv, prelu, norm,\n",
    "                                     pointwise_conv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [M, H, K]\n",
    "        Returns:\n",
    "            result: [M, B, K]\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"To ensure the output length is the same as the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [M, H, Kpad]\n",
    "        Returns:\n",
    "            [M, H, K]\n",
    "        \"\"\"\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "def chose_norm(norm_type, channel_size):\n",
    "    \"\"\"The input of normlization will be (M, C, K), where M is batch size,\n",
    "       C is channel size and K is sequence length.\n",
    "    \"\"\"\n",
    "    if norm_type == \"gLN\":\n",
    "        return GlobalLayerNorm(channel_size)\n",
    "    elif norm_type == \"cLN\":\n",
    "        return ChannelwiseLayerNorm(channel_size)\n",
    "    else: # norm_type == \"BN\":\n",
    "        # Given input (M, C, K), nn.BatchNorm1d(C) will accumulate statics\n",
    "        # along M and K, so this BN usage is right.\n",
    "        return nn.BatchNorm1d(channel_size)\n",
    "\n",
    "\n",
    "# TODO: Use nn.LayerNorm to impl cLN to speed up\n",
    "class ChannelwiseLayerNorm(nn.Module):\n",
    "    \"\"\"Channel-wise Layer Normalization (cLN)\"\"\"\n",
    "    def __init__(self, channel_size):\n",
    "        super(ChannelwiseLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.Tensor(1, channel_size, 1))  # [1, N, 1]\n",
    "        self.beta = nn.Parameter(torch.Tensor(1, channel_size,1 ))  # [1, N, 1]\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gamma.data.fill_(1)\n",
    "        self.beta.data.zero_()\n",
    "\n",
    "    def forward(self, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y: [M, N, K], M is batch size, N is channel size, K is length\n",
    "        Returns:\n",
    "            cLN_y: [M, N, K]\n",
    "        \"\"\"\n",
    "        #fatemeh : set float\n",
    "        y=y.float()\n",
    "        mean = torch.mean(y, dim=1, keepdim=True)  # [M, 1, K]\n",
    "        var = torch.var(y, dim=1, keepdim=True, unbiased=False)  # [M, 1, K]\n",
    "        cLN_y = self.gamma * (y - mean) / torch.pow(var + EPS, 0.5) + self.beta\n",
    "        return cLN_y\n",
    "\n",
    "\n",
    "class GlobalLayerNorm(nn.Module):\n",
    "    \"\"\"Global Layer Normalization (gLN)\"\"\"\n",
    "    def __init__(self, channel_size):\n",
    "        super(GlobalLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.Tensor(1, channel_size, 1))  # [1, N, 1]\n",
    "        self.beta = nn.Parameter(torch.Tensor(1, channel_size,1 ))  # [1, N, 1]\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gamma.data.fill_(1)\n",
    "        self.beta.data.zero_()\n",
    "\n",
    "    def forward(self, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y: [M, N, K], M is batch size, N is channel size, K is length\n",
    "        Returns:\n",
    "            gLN_y: [M, N, K]\n",
    "        \"\"\"\n",
    "        # TODO: in torch 1.0, torch.mean() support dim list\n",
    "        mean = y.mean(dim=1, keepdim=True).mean(dim=2, keepdim=True) #[M, 1, 1]\n",
    "        var = (torch.pow(y-mean, 2)).mean(dim=1, keepdim=True).mean(dim=2, keepdim=True)\n",
    "        gLN_y = self.gamma * (y - mean) / torch.pow(var + EPS, 0.5) + self.beta\n",
    "        return gLN_y\n",
    "#%%\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(123)\n",
    "    M, N, L, T = 2, 3, 4, 12\n",
    "    #K = (T-L)/(L/2)+1\n",
    "    K = 2*T//L-1\n",
    "    B, H, P, X, R, C, norm_type, causal = 2, 3, 3, 3, 2, 2, \"gLN\", False\n",
    "    mixture = torch.randint(3, (M, T))\n",
    "#%%\n",
    "    # test Encoder\n",
    "    encoder = Encoder(L, N)\n",
    "    encoder.conv1d_U.weight.data = torch.randint(2, encoder.conv1d_U.weight.size())\n",
    "    mixture_w = encoder(mixture)\n",
    "    print('mixture', mixture)\n",
    "    print('U', encoder.conv1d_U.weight)\n",
    "    print('mixture_w', mixture_w)\n",
    "    print('mixture_w size', mixture_w.size())\n",
    "#%%\n",
    "    # test TemporalConvNet\n",
    "    separator = TemporalConvNet(N, B, H, P, X, R, C, norm_type=norm_type, causal=causal)\n",
    "    est_mask = separator(mixture_w)\n",
    "    print('est_mask', est_mask)\n",
    "#%%\n",
    "    #fatemeh:error!!!with est_mask\n",
    "    # test Decoder\n",
    "    decoder = Decoder(N, L)\n",
    "    #est_mask = torch.randint(2, (B, K, C, N))\n",
    "    est_source = decoder(mixture_w, est_mask)\n",
    "    print('est_source', est_source)\n",
    "\n",
    "#%%\n",
    "    \n",
    "    #fatemeh: I put a mixture x as input instead of randint for mixture above\n",
    "    # test Conv-TasNet\n",
    "    import os\n",
    "    \n",
    "    audio_path='/home/speech/f_torch/bin/data/tr/mix/mix12_ff.wav'\n",
    "    import librosa\n",
    "    data, sr = librosa.load(audio_path)\n",
    "    x = torch.from_numpy(data)\n",
    "    mixture=x\n",
    "    x=x.reshape(2,len(mixture)//2)\n",
    "    \n",
    "    conv_tasnet = ConvTasNet(N, L, B, H, P, X, R, C, norm_type=norm_type)\n",
    "    est_source = conv_tasnet(x)\n",
    "    print('est_source', est_source)\n",
    "    print('est_source size', est_source.size())\n",
    "#%%\n",
    "    import matplotlib.pyplot as plt\n",
    "    import librosa\n",
    "    import numpy\n",
    "    mix_audio_path='/home/speech/f_torch/bin/data/tr/mix/mix12_ff.wav'\n",
    "    data, sr = librosa.load(mix_audio_path)\n",
    "    plt.figure()\n",
    "    plt.plot(data)\n",
    "    plt.title('mix')\n",
    "\n",
    "    import numpy as np\n",
    "    import soundfile as sf\n",
    "#data, sr = librosa.load(mix_audio_path)\n",
    "    d=est_source.detach().numpy()\n",
    "    samplerate=sr\n",
    "#rate = 44100\n",
    "#data = np.random.uniform(-1, 1, size=(rate * 10, 2))\n",
    "    s_path='est_source.wav'\n",
    "# Write out audio as 24bit PCM WAV\n",
    "\n",
    "#data, sr = librosa.load(s_path)\n",
    "#plt.figure()\n",
    "#plt.plot(data)\n",
    "#plt.title('s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Created on 2018/12\n",
    "# Author: Kaituo XU\n",
    "\n",
    "#import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "\n",
    "\n",
    "def preprocess_one_dir(in_dir, out_dir, out_filename, sample_rate=16000):\n",
    "    file_infos = []\n",
    "    in_dir = os.path.abspath(in_dir)\n",
    "    wav_list = os.listdir(in_dir)\n",
    "    for wav_file in wav_list:\n",
    "        if not wav_file.endswith('.wav'):\n",
    "            continue\n",
    "        wav_path = os.path.join(in_dir, wav_file)\n",
    "        samples, _ = librosa.load(wav_path, sr=sample_rate)\n",
    "        file_infos.append((wav_path, len(samples)))\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    with open(os.path.join(out_dir, out_filename + '.json'), 'w') as f:\n",
    "        json.dump(file_infos, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fatemeh#def preprocess(args):\n",
    "  #fatemeh#  for data_type in ['tr', 'cv', 'tt']:\n",
    "  #fatemeh#      for speaker in ['mix', 's1', 's2']:\n",
    "  #fatemeh#          preprocess_one_dir(os.path.join(args.in_dir, data_type, speaker),\n",
    "  #fatemeh#                             os.path.join(args.out_dir, data_type),\n",
    "  #fatemeh#                             speaker,\n",
    "  #fatemeh#                             sample_rate=args.sample_rate)\n",
    "            \n",
    "#fatemeh delete args\n",
    "def preprocess(in_dir,out_dir,sample_rate):\n",
    "    for data_type in ['tr', 'cv', 'tt']:\n",
    "        for speaker in ['mix', 's1', 's2']:\n",
    "            preprocess_one_dir(os.path.join(in_dir, data_type, speaker),\n",
    "                               os.path.join(out_dir, data_type),\n",
    "                               speaker,\n",
    "                               sample_rate=sample_rate)\n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    in_dir=\"/home/speech/f_torch/bin/data\"\n",
    "\n",
    "    out_dir=\"/home/speech/f_torch/bin/outdata\"\n",
    "    sample_rate=16000\n",
    "    preprocess(in_dir,out_dir,sample_rate)\n",
    "    #fatemeh#parser = argparse.ArgumentParser(\"WSJ0 data preprocessing\")\n",
    "    #fatemeh#parser.add_argument('--in-dir', type=str, default=None,\n",
    "    #fatemeh#                    help='Directory path of wsj0 including tr, cv and tt')\n",
    "    #fatemeh#parser.add_argument('--out-dir', type=str, default=None,\n",
    "    #fatemeh#                    help='Directory path to put output files')\n",
    "    #fatemeh#parser.add_argument('--sample-rate', type=int, default=8000,\n",
    "    #fatemeh#                    help='Sample rate of audio file')\n",
    "    #fatemeh#args = parser.parse_args()\n",
    "    #fatemeh#print(args)\n",
    "    #fatemeh#preprocess(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 0 utts(0.00 h) which is short than 16000 samples\n"
     ]
    }
   ],
   "source": [
    "# Created on 2018/12\n",
    "# Author: Kaituo XU\n",
    "\"\"\"\n",
    "Logic:\n",
    "1. AudioDataLoader generate a minibatch from AudioDataset, the size of this\n",
    "   minibatch is AudioDataLoader's batchsize. For now, we always set\n",
    "   AudioDataLoader's batchsize as 1. The real minibatch size we care about is\n",
    "   set in AudioDataset's __init__(...). So actually, we generate the\n",
    "   information of one minibatch in AudioDataset.\n",
    "2. After AudioDataLoader getting one minibatch from AudioDataset,\n",
    "   AudioDataLoader calls its collate_fn(batch) to process this minibatch.\n",
    "\n",
    "Input:\n",
    "    Mixtured WJS0 tr, cv and tt path\n",
    "Output:\n",
    "    One batch at a time.\n",
    "    Each inputs's shape is B x T\n",
    "    Each targets's shape is B x C x T\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import librosa\n",
    "\n",
    "\n",
    "class AudioDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, json_dir, batch_size, sample_rate=16000, segment=1, cv_maxlen=8.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_dir: directory including mix.json, s1.json and s2.json\n",
    "            segment: duration of audio segment, when set to -1, use full audio\n",
    "\n",
    "        xxx_infos is a list and each item is a tuple (wav_file, #samples)\n",
    "        \"\"\"\n",
    "        super(AudioDataset, self).__init__()\n",
    "        mix_json = os.path.join(json_dir, 'mix.json')\n",
    "        s1_json = os.path.join(json_dir, 's1.json')\n",
    "        s2_json = os.path.join(json_dir, 's2.json')\n",
    "        with open(mix_json, 'r') as f:\n",
    "            mix_infos = json.load(f)\n",
    "        with open(s1_json, 'r') as f:\n",
    "            s1_infos = json.load(f)\n",
    "        with open(s2_json, 'r') as f:\n",
    "            s2_infos = json.load(f)\n",
    "        # sort it by #samples (impl bucket)\n",
    "        def sort(infos): return sorted(\n",
    "            infos, key=lambda info: int(info[1]), reverse=True)\n",
    "        sorted_mix_infos = sort(mix_infos)\n",
    "        sorted_s1_infos = sort(s1_infos)\n",
    "        sorted_s2_infos = sort(s2_infos)\n",
    "        if segment >= 0.0:\n",
    "            # segment length and count dropped utts\n",
    "            segment_len = int(segment * sample_rate)  # 4s * 8000/s = 32000 samples\n",
    "            drop_utt, drop_len = 0, 0\n",
    "            for _, sample in sorted_mix_infos:\n",
    "                if sample < segment_len:\n",
    "                    drop_utt += 1\n",
    "                    drop_len += sample\n",
    "            print(\"Drop {} utts({:.2f} h) which is short than {} samples\".format(\n",
    "                drop_utt, drop_len/sample_rate/36000, segment_len))\n",
    "            # generate minibach infomations\n",
    "            minibatch = []\n",
    "            start = 0\n",
    "            while True:\n",
    "                num_segments = 0\n",
    "                end = start\n",
    "                part_mix, part_s1, part_s2 = [], [], []\n",
    "                while num_segments < batch_size and end < len(sorted_mix_infos):\n",
    "                    utt_len = int(sorted_mix_infos[end][1])\n",
    "                    if utt_len >= segment_len:  # skip too short utt\n",
    "                        num_segments += math.ceil(utt_len / segment_len)\n",
    "                        # Ensure num_segments is less than batch_size\n",
    "                        if num_segments > batch_size:\n",
    "                            # if num_segments of 1st audio > batch_size, skip it\n",
    "                            if start == end: end += 1\n",
    "                            break\n",
    "                        part_mix.append(sorted_mix_infos[end])\n",
    "                        part_s1.append(sorted_s1_infos[end])\n",
    "                        part_s2.append(sorted_s2_infos[end])\n",
    "                    end += 1\n",
    "                if len(part_mix) > 0:\n",
    "                    minibatch.append([part_mix, part_s1, part_s2,\n",
    "                                      sample_rate, segment_len])\n",
    "                if end == len(sorted_mix_infos):\n",
    "                    break\n",
    "                start = end\n",
    "            self.minibatch = minibatch\n",
    "        else:  # Load full utterance but not segment\n",
    "            # generate minibach infomations\n",
    "            minibatch = []\n",
    "            start = 0\n",
    "            while True:\n",
    "                end = min(len(sorted_mix_infos), start + batch_size)\n",
    "                # Skip long audio to avoid out-of-memory issue\n",
    "                if int(sorted_mix_infos[start][1]) > cv_maxlen * sample_rate:\n",
    "                    start = end\n",
    "                    continue\n",
    "                minibatch.append([sorted_mix_infos[start:end],\n",
    "                                  sorted_s1_infos[start:end],\n",
    "                                  sorted_s2_infos[start:end],\n",
    "                                  sample_rate, segment])\n",
    "                if end == len(sorted_mix_infos):\n",
    "                    break\n",
    "                start = end\n",
    "            self.minibatch = minibatch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.minibatch[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.minibatch)\n",
    "\n",
    "\n",
    "class AudioDataLoader(data.DataLoader):\n",
    "    \"\"\"\n",
    "    NOTE: just use batchsize=1 here, so drop_last=True makes no sense here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AudioDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = _collate_fn\n",
    "\n",
    "\n",
    "def _collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch: list, len(batch) = 1. See AudioDataset.__getitem__()\n",
    "    Returns:\n",
    "        mixtures_pad: B x T, torch.Tensor\n",
    "        ilens : B, torch.Tentor\n",
    "        sources_pad: B x C x T, torch.Tensor\n",
    "    \"\"\"\n",
    "    # batch should be located in list\n",
    "    assert len(batch) == 1\n",
    "    mixtures, sources = load_mixtures_and_sources(batch[0])\n",
    "\n",
    "    # get batch of lengths of input sequences\n",
    "    ilens = np.array([mix.shape[0] for mix in mixtures])\n",
    "\n",
    "    # perform padding and convert to tensor\n",
    "    pad_value = 0\n",
    "    mixtures_pad = pad_list([torch.from_numpy(mix).float()\n",
    "                             for mix in mixtures], pad_value)\n",
    "    ilens = torch.from_numpy(ilens)\n",
    "    sources_pad = pad_list([torch.from_numpy(s).float()\n",
    "                            for s in sources], pad_value)\n",
    "    # N x T x C -> N x C x T\n",
    "    sources_pad = sources_pad.permute((0, 2, 1)).contiguous()\n",
    "    return mixtures_pad, ilens, sources_pad\n",
    "\n",
    "\n",
    "# Eval data part\n",
    "from preprocess import preprocess_one_dir\n",
    "\n",
    "class EvalDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, mix_dir, mix_json, batch_size, sample_rate=16000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mix_dir: directory including mixture wav files\n",
    "            mix_json: json file including mixture wav files\n",
    "        \"\"\"\n",
    "        super(EvalDataset, self).__init__()\n",
    "        assert mix_dir != None or mix_json != None\n",
    "        if mix_dir is not None:\n",
    "            # Generate mix.json given mix_dir\n",
    "            preprocess_one_dir(mix_dir, mix_dir, 'mix',\n",
    "                               sample_rate=sample_rate)\n",
    "            mix_json = os.path.join(mix_dir, 'mix.json')\n",
    "        with open(mix_json, 'r') as f:\n",
    "            mix_infos = json.load(f)\n",
    "        # sort it by #samples (impl bucket)\n",
    "        def sort(infos): return sorted(\n",
    "            infos, key=lambda info: int(info[1]), reverse=True)\n",
    "        sorted_mix_infos = sort(mix_infos)\n",
    "        # generate minibach infomations\n",
    "        minibatch = []\n",
    "        start = 0\n",
    "        while True:\n",
    "            end = min(len(sorted_mix_infos), start + batch_size)\n",
    "            minibatch.append([sorted_mix_infos[start:end],\n",
    "                              sample_rate])\n",
    "            if end == len(sorted_mix_infos):\n",
    "                break\n",
    "            start = end\n",
    "        self.minibatch = minibatch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.minibatch[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.minibatch)\n",
    "\n",
    "\n",
    "class EvalDataLoader(data.DataLoader):\n",
    "    \"\"\"\n",
    "    NOTE: just use batchsize=1 here, so drop_last=True makes no sense here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(EvalDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = _collate_fn_eval\n",
    "\n",
    "\n",
    "def _collate_fn_eval(batch):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch: list, len(batch) = 1. See AudioDataset.__getitem__()\n",
    "    Returns:\n",
    "        mixtures_pad: B x T, torch.Tensor\n",
    "        ilens : B, torch.Tentor\n",
    "        filenames: a list contain B strings\n",
    "    \"\"\"\n",
    "    # batch should be located in list\n",
    "    assert len(batch) == 1\n",
    "    mixtures, filenames = load_mixtures(batch[0])\n",
    "\n",
    "    # get batch of lengths of input sequences\n",
    "    ilens = np.array([mix.shape[0] for mix in mixtures])\n",
    "\n",
    "    # perform padding and convert to tensor\n",
    "    pad_value = 0\n",
    "    mixtures_pad = pad_list([torch.from_numpy(mix).float()\n",
    "                             for mix in mixtures], pad_value)\n",
    "    ilens = torch.from_numpy(ilens)\n",
    "    return mixtures_pad, ilens, filenames\n",
    "\n",
    "\n",
    "# ------------------------------ utils ------------------------------------\n",
    "def load_mixtures_and_sources(batch):\n",
    "    \"\"\"\n",
    "    Each info include wav path and wav duration.\n",
    "    Returns:\n",
    "        mixtures: a list containing B items, each item is T np.ndarray\n",
    "        sources: a list containing B items, each item is T x C np.ndarray\n",
    "        T varies from item to item.\n",
    "    \"\"\"\n",
    "    mixtures, sources = [], []\n",
    "    mix_infos, s1_infos, s2_infos, sample_rate, segment_len = batch\n",
    "    # for each utterance\n",
    "    for mix_info, s1_info, s2_info in zip(mix_infos, s1_infos, s2_infos):\n",
    "        mix_path = mix_info[0]\n",
    "        s1_path = s1_info[0]\n",
    "        s2_path = s2_info[0]\n",
    "        assert mix_info[1] == s1_info[1] and s1_info[1] == s2_info[1]\n",
    "        # read wav file\n",
    "        mix, _ = librosa.load(mix_path, sr=sample_rate)\n",
    "        s1, _ = librosa.load(s1_path, sr=sample_rate)\n",
    "        s2, _ = librosa.load(s2_path, sr=sample_rate)\n",
    "        # merge s1 and s2\n",
    "        s = np.dstack((s1, s2))[0]  # T x C, C = 2\n",
    "        utt_len = mix.shape[-1]\n",
    "        if segment_len >= 0:\n",
    "            # segment\n",
    "            for i in range(0, utt_len - segment_len + 1, segment_len):\n",
    "                mixtures.append(mix[i:i+segment_len])\n",
    "                sources.append(s[i:i+segment_len])\n",
    "            if utt_len % segment_len != 0:\n",
    "                mixtures.append(mix[-segment_len:])\n",
    "                sources.append(s[-segment_len:])\n",
    "        else:  # full utterance\n",
    "            mixtures.append(mix)\n",
    "            sources.append(s)\n",
    "    return mixtures, sources\n",
    "\n",
    "\n",
    "def load_mixtures(batch):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        mixtures: a list containing B items, each item is T np.ndarray\n",
    "        filenames: a list containing B strings\n",
    "        T varies from item to item.\n",
    "    \"\"\"\n",
    "    mixtures, filenames = [], []\n",
    "    mix_infos, sample_rate = batch\n",
    "    # for each utterance\n",
    "    for mix_info in mix_infos:\n",
    "        mix_path = mix_info[0]\n",
    "        # read wav file\n",
    "        mix, _ = librosa.load(mix_path, sr=sample_rate)\n",
    "        mixtures.append(mix)\n",
    "        filenames.append(mix_path)\n",
    "    return mixtures, filenames\n",
    "\n",
    "\n",
    "def pad_list(xs, pad_value):\n",
    "    n_batch = len(xs)\n",
    "    max_len = max(x.size(0) for x in xs)\n",
    "    pad = xs[0].new(n_batch, max_len, * xs[0].size()[1:]).fill_(pad_value)\n",
    "    for i in range(n_batch):\n",
    "        pad[i, :xs[i].size(0)] = xs[i]\n",
    "    return pad\n",
    "\n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "#    import sys\n",
    "#    json_dir, batch_size = sys.argv[1:3]\n",
    "    #fatemeh\n",
    "    json_dir, batch_size='/home/speech/f_torch/bin/outdata/tr',1\n",
    "    dataset = AudioDataset(json_dir, int(batch_size))\n",
    "    data_loader = AudioDataLoader(dataset, batch_size=1,num_workers=0)\n",
    "    \n",
    "    for i, batch in enumerate(data_loader):\n",
    "        mixtures, lens, sources = batch\n",
    "        print(i)\n",
    "        print(mixtures.size())\n",
    "        print(sources.size())\n",
    "        print(lens)\n",
    "        if i < 10:\n",
    "            print(mixtures)\n",
    "            print(sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(data_loader):\n",
    "    mixtures, lens, sources = batch\n",
    "    print(i)\n",
    "    print(mixtures.size())\n",
    "    print(sources.size())\n",
    "    print(lens)\n",
    "    if i < 10:\n",
    "        print(mixtures)\n",
    "        print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AudioDataLoader at 0x7f53c6c98908>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pit_criterion.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created on 2018/12\n",
    "# Author: Kaituo XU\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "\n",
    "def cal_loss(source, estimate_source, source_lengths):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: [B, C, T], B is batch size\n",
    "        estimate_source: [B, C, T]\n",
    "        source_lengths: [B]\n",
    "    \"\"\"\n",
    "    max_snr, perms, max_snr_idx = cal_si_snr_with_pit(source,\n",
    "                                                      estimate_source,\n",
    "                                                      source_lengths)\n",
    "    loss = 0 - torch.mean(max_snr)\n",
    "    reorder_estimate_source = reorder_source(estimate_source, perms, max_snr_idx)\n",
    "    return loss, max_snr, estimate_source, reorder_estimate_source\n",
    "\n",
    "\n",
    "def cal_si_snr_with_pit(source, estimate_source, source_lengths):\n",
    "    \"\"\"Calculate SI-SNR with PIT training.\n",
    "    Args:\n",
    "        source: [B, C, T], B is batch size\n",
    "        estimate_source: [B, C, T]\n",
    "        source_lengths: [B], each item is between [0, T]\n",
    "    \"\"\"\n",
    "    assert source.size() == estimate_source.size()\n",
    "    B, C, T = source.size()\n",
    "    # mask padding position along T\n",
    "    mask = get_mask(source, source_lengths)\n",
    "    estimate_source *= mask\n",
    "\n",
    "    # Step 1. Zero-mean norm\n",
    "    num_samples = source_lengths.view(-1, 1, 1).float()  # [B, 1, 1]\n",
    "    mean_target = torch.sum(source, dim=2, keepdim=True) / num_samples\n",
    "    mean_estimate = torch.sum(estimate_source, dim=2, keepdim=True) / num_samples\n",
    "    zero_mean_target = source - mean_target\n",
    "    zero_mean_estimate = estimate_source - mean_estimate\n",
    "    # mask padding position along T\n",
    "    zero_mean_target *= mask\n",
    "    zero_mean_estimate *= mask\n",
    "\n",
    "    # Step 2. SI-SNR with PIT\n",
    "    # reshape to use broadcast\n",
    "    s_target = torch.unsqueeze(zero_mean_target, dim=1)  # [B, 1, C, T]\n",
    "    s_estimate = torch.unsqueeze(zero_mean_estimate, dim=2)  # [B, C, 1, T]\n",
    "    # s_target = <s', s>s / ||s||^2\n",
    "    pair_wise_dot = torch.sum(s_estimate * s_target, dim=3, keepdim=True)  # [B, C, C, 1]\n",
    "    s_target_energy = torch.sum(s_target ** 2, dim=3, keepdim=True) + EPS  # [B, 1, C, 1]\n",
    "    pair_wise_proj = pair_wise_dot * s_target / s_target_energy  # [B, C, C, T]\n",
    "    # e_noise = s' - s_target\n",
    "    e_noise = s_estimate - pair_wise_proj  # [B, C, C, T]\n",
    "    # SI-SNR = 10 * log_10(||s_target||^2 / ||e_noise||^2)\n",
    "    pair_wise_si_snr = torch.sum(pair_wise_proj ** 2, dim=3) / (torch.sum(e_noise ** 2, dim=3) + EPS)\n",
    "    pair_wise_si_snr = 10 * torch.log10(pair_wise_si_snr + EPS)  # [B, C, C]\n",
    "\n",
    "    # Get max_snr of each utterance\n",
    "    # permutations, [C!, C]\n",
    "    perms = source.new_tensor(list(permutations(range(C))), dtype=torch.long)\n",
    "    # one-hot, [C!, C, C]\n",
    "    index = torch.unsqueeze(perms, 2)\n",
    "    perms_one_hot = source.new_zeros((*perms.size(), C)).scatter_(2, index, 1)\n",
    "    # [B, C!] <- [B, C, C] einsum [C!, C, C], SI-SNR sum of each permutation\n",
    "    snr_set = torch.einsum('bij,pij->bp', [pair_wise_si_snr, perms_one_hot])\n",
    "    max_snr_idx = torch.argmax(snr_set, dim=1)  # [B]\n",
    "    # max_snr = torch.gather(snr_set, 1, max_snr_idx.view(-1, 1))  # [B, 1]\n",
    "    max_snr, _ = torch.max(snr_set, dim=1, keepdim=True)\n",
    "    max_snr /= C\n",
    "    return max_snr, perms, max_snr_idx\n",
    "\n",
    "\n",
    "def reorder_source(source, perms, max_snr_idx):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: [B, C, T]\n",
    "        perms: [C!, C], permutations\n",
    "        max_snr_idx: [B], each item is between [0, C!)\n",
    "    Returns:\n",
    "        reorder_source: [B, C, T]\n",
    "    \"\"\"\n",
    "    B, C, *_ = source.size()\n",
    "    # [B, C], permutation whose SI-SNR is max of each utterance\n",
    "    # for each utterance, reorder estimate source according this permutation\n",
    "    max_snr_perm = torch.index_select(perms, dim=0, index=max_snr_idx)\n",
    "    # print('max_snr_perm', max_snr_perm)\n",
    "    # maybe use torch.gather()/index_select()/scatter() to impl this?\n",
    "    reorder_source = torch.zeros_like(source)\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            reorder_source[b, c] = source[b, max_snr_perm[b][c]]\n",
    "    return reorder_source\n",
    "\n",
    "\n",
    "def get_mask(source, source_lengths):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: [B, C, T]\n",
    "        source_lengths: [B]\n",
    "    Returns:\n",
    "        mask: [B, 1, T]\n",
    "    \"\"\"\n",
    "    B, _, T = source.size()\n",
    "    mask = source.new_ones((B, 1, T))\n",
    "    for i in range(B):\n",
    "        mask[i, :, source_lengths[i]:] = 0\n",
    "    return mask\n",
    "\n",
    "#%%\n",
    "    \n",
    "####fatemeh#error: long , float but is ok on google colab\n",
    "#if __name__ == \"__main__\":\n",
    "#    torch.manual_seed(123)\n",
    "#    B, C, T = 2, 3, 12\n",
    "#    # fake data\n",
    "#    source = torch.randint(4, (B, C, T))\n",
    "#    estimate_source = torch.randint(4, (B, C, T))\n",
    "#    source[1, :, -3:] = 0\n",
    "#    estimate_source[1, :, -3:] = 0\n",
    "#    source_lengths = torch.LongTensor([T, T-3])\n",
    "#    print('source', source)\n",
    "#    print('estimate_source', estimate_source)\n",
    "#    print('source_lengths', source_lengths)\n",
    "#    \n",
    "#    #source_lengths=source_lengths.float()\n",
    "#    loss, max_snr, estimate_source, reorder_estimate_source = cal_loss(source, estimate_source, source_lengths)\n",
    "#    print('loss', loss)\n",
    "#    print('max_snr', max_snr)\n",
    "#    print('reorder_estimate_source', reorder_estimate_source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solverr.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 25 20:24:17 2020\n",
    "\n",
    "@author: fatemeh nourian\n",
    "\"\"\"\n",
    "\n",
    "#my first attempt to train convTasNet - 99/06/04\n",
    "# General config\n",
    "# Task related\n",
    "train_dir='/home/speech/f_torch/bin/outdata/tr'\n",
    "valid_dir='/home/speech/f_torch/bin/outdata/cv'\n",
    "sample_rate=16000\n",
    "segment=-1\n",
    "cv_maxlen=8\n",
    "# Network architecture\n",
    "N=256\n",
    "#Number of filters in autoencoder\n",
    "L=20\n",
    "#Length of the filters in samples (40=5ms at 8kHZ)\n",
    "B=256\n",
    "#Number of channels in bottleneck 1 × 1-conv block\n",
    "H=512\n",
    "#Number of channels in convolutional blocks\n",
    "P=3\n",
    "#Kernel size in convolutional blocks\n",
    "X=8\n",
    "#Number of convolutional blocks in each repeat\n",
    "R=4\n",
    "#Number of repeats\n",
    "C=2\n",
    "#Number of speakers\n",
    "norm_type='gLN'\n",
    "#Layer norm type:['gLN', 'cLN', 'BN']\n",
    "causal=0\n",
    "#Causal (1) or noncausal(0) training\n",
    "mask_nonlinear='relu'\n",
    "#non-linear to generate mask:['relu','softmax']\n",
    "# Training config\n",
    "use_cuda=0\n",
    "#Whether use GPU, default=1\n",
    "epochs=30\n",
    "#Number of maximum epochs\n",
    "half_lr=0\n",
    "#Halving learning rate when get small improvement\n",
    "early_stop=0\n",
    "#Early stop training when no improvement for 10 epochs\n",
    "max_norm=5\n",
    "#Gradient norm threshold to clip\n",
    "# minibatch\n",
    "shuffle=0\n",
    "#reshuffle the data at every epoch\n",
    "batch_size=128\n",
    "num_workers=0\n",
    "#Number of workers to generate minibatch\n",
    "# optimizer\n",
    "optimizer='adam'\n",
    "#['sgd', 'adam']\n",
    "lr=1e-3\n",
    "#Init learning rate\n",
    "momentum=0.0\n",
    "#Momentum for optimizer\n",
    "l2=0.0\n",
    "#weight decay (L2 penalty)\n",
    "# save and load model\n",
    "save_folder='exp/temp'\n",
    "#Location to save epoch models\n",
    "checkpoint=0\n",
    "#Enables checkpoint saving of model\n",
    "continue_from=''\n",
    "#Continue from checkpoint model\n",
    "model_path='final.pth.tar'\n",
    "#Location to save best validation model\n",
    "# logging\n",
    "print_freq=10\n",
    "#Frequency of printing training infomation\n",
    "visdom=0\n",
    "#Turn on visdom graphing\n",
    "visdom_epoch=0\n",
    "#Turn on visdom graphing each epoch\n",
    "visdom_id='TasNet training'\n",
    "#Identifier for visdom run\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from pit_criterion import cal_loss\n",
    "\n",
    "\n",
    "class Solver(object):\n",
    "    \n",
    "    def __init__(self, data, model, optimizer, use_cuda,epochs,half_lr,early_stop,max_norm,save_folder,checkpoint,continue_from,model_path,print_freq,visdom,visdom_epoch,visdom_id):\n",
    "        self.tr_loader = data['tr_loader']\n",
    "        self.cv_loader = data['cv_loader']\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # Training config\n",
    "        self.use_cuda = use_cuda\n",
    "        self.epochs = epochs\n",
    "        self.half_lr = half_lr\n",
    "        self.early_stop = early_stop\n",
    "        self.max_norm = max_norm\n",
    "        # save and load model\n",
    "        self.save_folder = save_folder\n",
    "        self.checkpoint = checkpoint\n",
    "        self.continue_from = continue_from\n",
    "        self.model_path = model_path\n",
    "        # logging\n",
    "        self.print_freq = print_freq\n",
    "        # visualizing loss using visdom\n",
    "        self.tr_loss = torch.Tensor(self.epochs)\n",
    "        self.cv_loss = torch.Tensor(self.epochs)\n",
    "        self.visdom = visdom\n",
    "        self.visdom_epoch = visdom_epoch\n",
    "        self.visdom_id = visdom_id\n",
    "        if self.visdom:\n",
    "            from visdom import Visdom\n",
    "            self.vis = Visdom(env=self.visdom_id)\n",
    "            self.vis_opts = dict(title=self.visdom_id,\n",
    "                                 ylabel='Loss', xlabel='Epoch',\n",
    "                                 legend=['train loss', 'cv loss'])\n",
    "            self.vis_window = None\n",
    "            self.vis_epochs = torch.arange(1, self.epochs + 1)\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        # Reset\n",
    "        if self.continue_from:\n",
    "            print('Loading checkpoint model %s' % self.continue_from)\n",
    "            package = torch.load(self.continue_from)\n",
    "            self.model.module.load_state_dict(package['state_dict'])\n",
    "            self.optimizer.load_state_dict(package['optim_dict'])\n",
    "            self.start_epoch = int(package.get('epoch', 1))\n",
    "            self.tr_loss[:self.start_epoch] = package['tr_loss'][:self.start_epoch]\n",
    "            self.cv_loss[:self.start_epoch] = package['cv_loss'][:self.start_epoch]\n",
    "        else:\n",
    "            self.start_epoch = 0\n",
    "        # Create save folder\n",
    "        os.makedirs(self.save_folder, exist_ok=True)\n",
    "        self.prev_val_loss = float(\"inf\")\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.halving = False\n",
    "        self.val_no_impv = 0\n",
    "\n",
    "    def train(self):\n",
    "        # Train model multi-epoches\n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "            # Train one epoch\n",
    "            print(\"Training...\")\n",
    "            self.model.train()  # Turn on BatchNorm & Dropout\n",
    "            start = time.time()\n",
    "            tr_avg_loss = self._run_one_epoch(epoch)\n",
    "            print('-' * 85)\n",
    "            print('Train Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
    "                  'Train Loss {2:.3f}'.format(\n",
    "                      epoch + 1, time.time() - start, tr_avg_loss))\n",
    "            print('-' * 85)\n",
    "\n",
    "            # Save model each epoch\n",
    "            if self.checkpoint:\n",
    "                file_path = os.path.join(\n",
    "                    self.save_folder, 'epoch%d.pth.tar' % (epoch + 1))\n",
    "                torch.save(self.model.module.serialize(self.model.module,\n",
    "                                                       self.optimizer, epoch + 1,\n",
    "                                                       tr_loss=self.tr_loss,\n",
    "                                                       cv_loss=self.cv_loss),\n",
    "                           file_path)\n",
    "                print('Saving checkpoint model to %s' % file_path)\n",
    "\n",
    "            # Cross validation\n",
    "            print('Cross validation...')\n",
    "            self.model.eval()  # Turn off Batchnorm & Dropout\n",
    "            val_loss = self._run_one_epoch(epoch, cross_valid=True)\n",
    "            print('-' * 85)\n",
    "            print('Valid Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
    "                  'Valid Loss {2:.3f}'.format(\n",
    "                      epoch + 1, time.time() - start, val_loss))\n",
    "            print('-' * 85)\n",
    "\n",
    "            # Adjust learning rate (halving)\n",
    "            if self.half_lr:\n",
    "                if val_loss >= self.prev_val_loss:\n",
    "                    self.val_no_impv += 1\n",
    "                    if self.val_no_impv >= 3:\n",
    "                        self.halving = True\n",
    "                    if self.val_no_impv >= 10 and self.early_stop:\n",
    "                        print(\"No imporvement for 10 epochs, early stopping.\")\n",
    "                        break\n",
    "                else:\n",
    "                    self.val_no_impv = 0\n",
    "            if self.halving:\n",
    "                optim_state = self.optimizer.state_dict()\n",
    "                optim_state['param_groups'][0]['lr'] = \\\n",
    "                    optim_state['param_groups'][0]['lr'] / 2.0\n",
    "                self.optimizer.load_state_dict(optim_state)\n",
    "                print('Learning rate adjusted to: {lr:.6f}'.format(\n",
    "                    lr=optim_state['param_groups'][0]['lr']))\n",
    "                self.halving = False\n",
    "            self.prev_val_loss = val_loss\n",
    "\n",
    "            # Save the best model\n",
    "            self.tr_loss[epoch] = tr_avg_loss\n",
    "            self.cv_loss[epoch] = val_loss\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                file_path = os.path.join(self.save_folder, self.model_path)\n",
    "                torch.save(self.model.module.serialize(self.model.module,\n",
    "                                                       self.optimizer, epoch + 1,\n",
    "                                                       tr_loss=self.tr_loss,\n",
    "                                                       cv_loss=self.cv_loss),\n",
    "                           file_path)\n",
    "                print(\"Find better validated model, saving to %s\" % file_path)\n",
    "\n",
    "            # visualizing loss using visdom\n",
    "            if self.visdom:\n",
    "                x_axis = self.vis_epochs[0:epoch + 1]\n",
    "                y_axis = torch.stack(\n",
    "                    (self.tr_loss[0:epoch + 1], self.cv_loss[0:epoch + 1]), dim=1)\n",
    "                if self.vis_window is None:\n",
    "                    self.vis_window = self.vis.line(\n",
    "                        X=x_axis,\n",
    "                        Y=y_axis,\n",
    "                        opts=self.vis_opts,\n",
    "                    )\n",
    "                else:\n",
    "                    self.vis.line(\n",
    "                        X=x_axis.unsqueeze(0).expand(y_axis.size(\n",
    "                            1), x_axis.size(0)).transpose(0, 1),  # Visdom fix\n",
    "                        Y=y_axis,\n",
    "                        win=self.vis_window,\n",
    "                        update='replace',\n",
    "                    )\n",
    "\n",
    "    def _run_one_epoch(self, epoch, cross_valid=False):\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        data_loader = self.tr_loader if not cross_valid else self.cv_loader\n",
    "\n",
    "        # visualizing loss using visdom\n",
    "        if self.visdom_epoch and not cross_valid:\n",
    "            vis_opts_epoch = dict(title=self.visdom_id + \" epoch \" + str(epoch),\n",
    "                                  ylabel='Loss', xlabel='Epoch')\n",
    "            vis_window_epoch = None\n",
    "            vis_iters = torch.arange(1, len(data_loader) + 1)\n",
    "            vis_iters_loss = torch.Tensor(len(data_loader))\n",
    "\n",
    "        for i, (data) in enumerate(data_loader):\n",
    "            padded_mixture, mixture_lengths, padded_source = data\n",
    "            if self.use_cuda:\n",
    "                padded_mixture = padded_mixture.cuda()\n",
    "                mixture_lengths = mixture_lengths.cuda()\n",
    "                padded_source = padded_source.cuda()\n",
    "            estimate_source = self.model(padded_mixture)\n",
    "            loss, max_snr, estimate_source, reorder_estimate_source = \\\n",
    "                cal_loss(padded_source, estimate_source, mixture_lengths)\n",
    "            if not cross_valid:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(),\n",
    "                                               self.max_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if i % self.print_freq == 0:\n",
    "                print('Epoch {0} | Iter {1} | Average Loss {2:.3f} | '\n",
    "                      'Current Loss {3:.6f} | {4:.1f} ms/batch'.format(\n",
    "                          epoch + 1, i + 1, total_loss / (i + 1),\n",
    "                          loss.item(), 1000 * (time.time() - start) / (i + 1)),\n",
    "                      flush=True)\n",
    "\n",
    "            # visualizing loss using visdom\n",
    "            if self.visdom_epoch and not cross_valid:\n",
    "                vis_iters_loss[i] = loss.item()\n",
    "                if i % self.print_freq == 0:\n",
    "                    x_axis = vis_iters[:i+1]\n",
    "                    y_axis = vis_iters_loss[:i+1]\n",
    "                    if vis_window_epoch is None:\n",
    "                        vis_window_epoch = self.vis.line(X=x_axis, Y=y_axis,\n",
    "                                                         opts=vis_opts_epoch)\n",
    "                    else:\n",
    "                        self.vis.line(X=x_axis, Y=y_axis, win=vis_window_epoch,\n",
    "                                      update='replace')\n",
    "\n",
    "        return total_loss / (i + 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11_train.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvTasNet(\n",
      "  (encoder): Encoder(\n",
      "    (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)\n",
      "  )\n",
      "  (separator): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): ChannelwiseLayerNorm()\n",
      "      (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (2): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (basis_signals): Linear(in_features=256, out_features=20, bias=False)\n",
      "  )\n",
      ")\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Iter 1 | Average Loss 42.288 | Current Loss 42.287910 | 117851.4 ms/batch\n",
      "-------------------------------------------------------------------------------------\n",
      "Train Summary | End of Epoch 1 | Time 117.90s | Train Loss 42.288\n",
      "-------------------------------------------------------------------------------------\n",
      "Cross validation...\n",
      "Epoch 1 | Iter 1 | Average Loss 30.359 | Current Loss 30.358755 | 2615.6 ms/batch\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dba6f2b0dd0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m    \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_maxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_nonlinear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m#    args = parser.parse_args()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-dba6f2b0dd0a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_dir, batch_size, sample_rate, segment, valid_dir, cv_maxlen, shuffle, num_workers, N, L, B, H, P, X, R, C, norm_type, causal, mask_nonlinear, use_cuda, optimizer, lr, momentum, l2)\u001b[0m\n\u001b[1;32m    129\u001b[0m    \u001b[0;31m# solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m    \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalf_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontinue_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisdom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisdom_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisdom_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m    \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-f918134fe9e1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross validation...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Turn off Batchnorm & Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             print('Valid Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
      "\u001b[0;32m<ipython-input-32-f918134fe9e1>\u001b[0m in \u001b[0;36m_run_one_epoch\u001b[0;34m(self, epoch, cross_valid)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mvis_iters_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mpadded_mixture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixture_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-d46eea449ba1>\u001b[0m in \u001b[0;36m_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mpad_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     mixtures_pad = pad_list([torch.from_numpy(mix).float()\n\u001b[0;32m--> 150\u001b[0;31m                              for mix in mixtures], pad_value)\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0milens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0milens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     sources_pad = pad_list([torch.from_numpy(s).float()\n",
      "\u001b[0;32m<ipython-input-28-d46eea449ba1>\u001b[0m in \u001b[0;36mpad_list\u001b[0;34m(xs, pad_value)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpad_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mn_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    " # -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 25 20:02:59 2020\n",
    "@author: fatemeh nourian\n",
    "\"\"\"\n",
    "\n",
    "#my first attempt to train convTasNet - 99/06/04\n",
    "\n",
    "import torch\n",
    "\n",
    "#from data import AudioDataLoader, AudioDataset\n",
    "#from solverr import Solver\n",
    "#from conv_tasnet import ConvTasNet\n",
    "\n",
    "# General config\n",
    "# Task related\n",
    "train_dir='/home/speech/f_torch/bin/stream_data/outdata/tr'\n",
    "#directory including mix.json, s1.json and s2.json\n",
    "valid_dir='/home/speech/f_torch/bin/stream_data/outdata/cv'\n",
    "sample_rate=16000\n",
    "segment=-1\n",
    "#Segment length (seconds)\n",
    "cv_maxlen=8\n",
    "#max audio length (seconds) in cv, to avoid OOM issue\n",
    "# Network architecture\n",
    "N=256\n",
    "#Number of filters in autoencoder\n",
    "L=20\n",
    "#Length of the filters in samples (40=5ms at 8kHZ)\n",
    "B=256\n",
    "#Number of channels in bottleneck 1 × 1-conv block\n",
    "H=512\n",
    "#Number of channels in convolutional blocks\n",
    "P=3\n",
    "#Kernel size in convolutional blocks\n",
    "X=8\n",
    "#Number of convolutional blocks in each repeat\n",
    "R=4\n",
    "#Number of repeats\n",
    "C=2\n",
    "#Number of speakers\n",
    "norm_type='cLN'\n",
    "#Layer norm type:['gLN', 'cLN', 'BN']\n",
    "causal=1\n",
    "#Causal (1) or noncausal(0) training\n",
    "mask_nonlinear='relu'\n",
    "#non-linear to generate mask:['relu','softmax']\n",
    "# Training config\n",
    "use_cuda=0\n",
    "#Whether use GPU, default=1\n",
    "epochs=30\n",
    "#Number of maximum epochs\n",
    "half_lr=0\n",
    "#Halving learning rate when get small improvement\n",
    "early_stop=0\n",
    "#Early stop training when no improvement for 10 epochs\n",
    "max_norm=5\n",
    "#Gradient norm threshold to clip\n",
    "# minibatch\n",
    "shuffle=0\n",
    "#reshuffle the data at every epoch\n",
    "batch_size=128\n",
    "num_workers=4\n",
    "#Number of workers to generate minibatch\n",
    "# optimizer\n",
    "optimizer='adam'\n",
    "#['sgd', 'adam']\n",
    "lr=1e-3\n",
    "#Init learning rate\n",
    "momentum=0.0\n",
    "#Momentum for optimizer\n",
    "l2=0.0\n",
    "#weight decay (L2 penalty)\n",
    "# save and load model\n",
    "save_folder='exp/temp'\n",
    "#Location to save epoch models\n",
    "checkpoint=0\n",
    "#Enables checkpoint saving of model\n",
    "continue_from=''\n",
    "#Continue from checkpoint model\n",
    "model_path='final.pth.tar'\n",
    "#Location to save best validation model\n",
    "# logging\n",
    "print_freq=10\n",
    "#Frequency of printing training infomation\n",
    "visdom=0\n",
    "#Turn on visdom graphing\n",
    "visdom_epoch=0\n",
    "#Turn on visdom graphing each epoch\n",
    "visdom_id='TasNet training'\n",
    "#Identifier for visdom run\n",
    "\n",
    "def main(train_dir,batch_size,sample_rate, segment,valid_dir,cv_maxlen,shuffle,num_workers,N, L, B, H, P, X, R, C,norm_type, causal, mask_nonlinear,use_cuda,optimizer,lr,momentum,l2):\n",
    "     # Construct Solver\n",
    "    # data\n",
    "    tr_dataset = AudioDataset(train_dir, batch_size,\n",
    "                              sample_rate=sample_rate, segment=segment)\n",
    "    cv_dataset = AudioDataset(valid_dir, batch_size=1,  # 1 -> use less GPU memory to do cv\n",
    "                              sample_rate=sample_rate,\n",
    "                              segment=-1, cv_maxlen=cv_maxlen)  # -1 -> use full audio\n",
    "    tr_loader = AudioDataLoader(tr_dataset, batch_size=1,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=num_workers)\n",
    "    cv_loader = AudioDataLoader(cv_dataset, batch_size=1,\n",
    "                                num_workers=0)\n",
    "    data = {'tr_loader': tr_loader, 'cv_loader': cv_loader}\n",
    "    # model\n",
    "    model = ConvTasNet(N, L, B, H, P, X, R, C, \n",
    "                       norm_type=norm_type, causal=causal,\n",
    "                       mask_nonlinear=mask_nonlinear)\n",
    "    print(model)\n",
    "    if use_cuda:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.cuda()\n",
    "    # optimizer\n",
    "    if optimizer == 'sgd':\n",
    "        optimizier = torch.optim.SGD(model.parameters(),\n",
    "                                     lr=lr,\n",
    "                                     momentum=momentum,\n",
    "                                     weight_decay=l2)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizier = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=lr,\n",
    "                                      weight_decay=l2)\n",
    "    else:\n",
    "        print(\"Not support optimizer\")\n",
    "        return\n",
    "\n",
    "    # solver\n",
    "    solver = Solver(data, model, optimizier, use_cuda,epochs,half_lr,early_stop,max_norm,save_folder,checkpoint,continue_from,model_path,print_freq,visdom,visdom_epoch,visdom_id)\n",
    "    solver.train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "if __name__ == '__main__':\n",
    "    main(train_dir,batch_size,sample_rate, segment,valid_dir,cv_maxlen,shuffle,num_workers,N, L, B, H, P, X, R, C,norm_type, causal, mask_nonlinear,use_cuda,optimizer,lr,momentum,l2)\n",
    "    \n",
    "#    args = parser.parse_args()\n",
    "#    print(args)\n",
    "#    main(args)\n",
    "#    main(train_dir,batch_size,sample_rate, segment,valid_dir,cv_maxlen,shuffle,num_workers,N, L, B, H, P, X, R, C,norm_type, causal, mask_nonlinear,use_cuda,optimizer,lr,momentum,l2)\n",
    "    \n",
    "#%%\n",
    "#fatemeh\n",
    "#if __name__ == '__main__':\n",
    "#    model = ConvTasNet(N, L, B, H, P, X, R, C,norm_type=norm_type, causal=causal,mask_nonlinear=mask_nonlinear)\n",
    "    #criterion=nn.\n",
    "\n",
    "\n",
    "\n",
    "##print(model)\n",
    "#optimizier = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=l2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvTasNet(\n",
      "  (encoder): Encoder(\n",
      "    (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)\n",
      "  )\n",
      "  (separator): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): ChannelwiseLayerNorm()\n",
      "      (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (2): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (5): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (6): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (7): TemporalBlock(\n",
      "            (net): Sequential(\n",
      "              (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "              (1): PReLU(num_parameters=1)\n",
      "              (2): ChannelwiseLayerNorm()\n",
      "              (3): DepthwiseSeparableConv(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,), groups=512, bias=False)\n",
      "                  (1): Chomp1d()\n",
      "                  (2): PReLU(num_parameters=1)\n",
      "                  (3): ChannelwiseLayerNorm()\n",
      "                  (4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (basis_signals): Linear(in_features=256, out_features=20, bias=False)\n",
      "  )\n",
      ")\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Iter 1 | Average Loss 41.042 | Current Loss 41.042000 | 329.0 ms/batch\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/speech/f_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-8-d46eea449ba1>\", line 150, in _collate_fn\n    for mix in mixtures], pad_value)\n  File \"<ipython-input-8-d46eea449ba1>\", line 295, in pad_list\n    max_len = max(x.size(0) for x in xs)\nValueError: max() arg is an empty sequence\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e0d7b86d846e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalf_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontinue_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisdom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisdom_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisdom_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-f918134fe9e1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Turn on BatchNorm & Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mtr_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             print('Train Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
      "\u001b[0;32m<ipython-input-11-f918134fe9e1>\u001b[0m in \u001b[0;36m_run_one_epoch\u001b[0;34m(self, epoch, cross_valid)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mvis_iters_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mpadded_mixture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixture_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/f_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/home/speech/f_torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-8-d46eea449ba1>\", line 150, in _collate_fn\n    for mix in mixtures], pad_value)\n  File \"<ipython-input-8-d46eea449ba1>\", line 295, in pad_list\n    max_len = max(x.size(0) for x in xs)\nValueError: max() arg is an empty sequence\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "tr_dataset = AudioDataset(train_dir, batch_size, sample_rate=sample_rate, segment=segment)\n",
    "cv_dataset = AudioDataset(valid_dir, batch_size=1, sample_rate=sample_rate, segment=-1, cv_maxlen=cv_maxlen)\n",
    "#segment   # -1 -> use full audio\n",
    "#batch_size=1 -> use less GPU memory to do cv\n",
    "\n",
    "tr_loader = AudioDataLoader(tr_dataset, batch_size=1, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "cv_loader = AudioDataLoader(cv_dataset, batch_size=1, num_workers=0)\n",
    "\n",
    "data = {'tr_loader': tr_loader, 'cv_loader': cv_loader}\n",
    "\n",
    "model = ConvTasNet(N, L, B, H, P, X, R, C, norm_type=norm_type, causal=causal,mask_nonlinear=mask_nonlinear)\n",
    "print(model)\n",
    "\n",
    "if use_cuda:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "# optimizer\n",
    "if optimizer == 'sgd':\n",
    "    optimizier = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum,weight_decay=l2)\n",
    "elif optimizer == 'adam':\n",
    "    optimizier = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n",
    "else:\n",
    "    print(\"Not support optimizer\")\n",
    "    \n",
    "solver = Solver(data, model, optimizier, use_cuda,epochs,half_lr,early_stop,max_norm,save_folder,checkpoint,continue_from,model_path,print_freq,visdom,visdom_epoch,visdom_id)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 23 14:27:30 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 415.18       Driver Version: 415.18       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   41C    P8    14W / 180W |   4291MiB /  8116MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      2019      G   /usr/lib/xorg/Xorg                            18MiB |\r\n",
      "|    0      2074      G   /usr/bin/gnome-shell                          48MiB |\r\n",
      "|    0      2306      G   /usr/lib/xorg/Xorg                           118MiB |\r\n",
      "|    0      2437      G   /usr/bin/gnome-shell                         151MiB |\r\n",
      "|    0      5043      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files    69MiB |\r\n",
      "|    0     26335      C   /home/speech/f_torch/bin/python             3879MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.ones([2, 4]).cuda\n",
    "b=torch.ones([2, 4]).cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_run_one_epoch() missing 1 required positional argument: 'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-37603b904b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Turn on BatchNorm & Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtr_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             print('Train Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
      "\u001b[0;31mTypeError\u001b[0m: _run_one_epoch() missing 1 required positional argument: 'epoch'"
     ]
    }
   ],
   "source": [
    "epoch=5\n",
    "for epoch in range(5):\n",
    "            # Train one epoch\n",
    "            print(\"Training...\")\n",
    "            model.train()  # Turn on BatchNorm & Dropout\n",
    "            start = time.time()\n",
    "            tr_avg_loss = _run_one_epoch(epoch)\n",
    "            print('-' * 85)\n",
    "            print('Train Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
    "                  'Train Loss {2:.3f}'.format(\n",
    "                      epoch + 1, time.time() - start, tr_avg_loss))\n",
    "            print('-' * 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _run_one_epoch(self, epoch, cross_valid=False):\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        data_loader = self.tr_loader if not cross_valid else self.cv_loader\n",
    "\n",
    "        # visualizing loss using visdom\n",
    "        if self.visdom_epoch and not cross_valid:\n",
    "            vis_opts_epoch = dict(title=self.visdom_id + \" epoch \" + str(epoch),\n",
    "                                  ylabel='Loss', xlabel='Epoch')\n",
    "            vis_window_epoch = None\n",
    "            vis_iters = torch.arange(1, len(data_loader) + 1)\n",
    "            vis_iters_loss = torch.Tensor(len(data_loader))\n",
    "\n",
    "        for i, (data) in enumerate(data_loader):\n",
    "            padded_mixture, mixture_lengths, padded_source = data\n",
    "            if self.use_cuda:\n",
    "                padded_mixture = padded_mixture.cuda()\n",
    "                mixture_lengths = mixture_lengths.cuda()\n",
    "                padded_source = padded_source.cuda()\n",
    "            estimate_source = self.model(padded_mixture)\n",
    "            loss, max_snr, estimate_source, reorder_estimate_source = \\\n",
    "                cal_loss(padded_source, estimate_source, mixture_lengths)\n",
    "            if not cross_valid:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(),\n",
    "                                               self.max_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if i % self.print_freq == 0:\n",
    "                print('Epoch {0} | Iter {1} | Average Loss {2:.3f} | '\n",
    "                      'Current Loss {3:.6f} | {4:.1f} ms/batch'.format(\n",
    "                          epoch + 1, i + 1, total_loss / (i + 1),\n",
    "                          loss.item(), 1000 * (time.time() - start) / (i + 1)),\n",
    "                      flush=True)\n",
    "\n",
    "            # visualizing loss using visdom\n",
    "            if self.visdom_epoch and not cross_valid:\n",
    "                vis_iters_loss[i] = loss.item()\n",
    "                if i % self.print_freq == 0:\n",
    "                    x_axis = vis_iters[:i+1]\n",
    "                    y_axis = vis_iters_loss[:i+1]\n",
    "                    if vis_window_epoch is None:\n",
    "                        vis_window_epoch = self.vis.line(X=x_axis, Y=y_axis,\n",
    "                                                         opts=vis_opts_epoch)\n",
    "                    else:\n",
    "                        self.vis.line(X=x_axis, Y=y_axis, win=vis_window_epoch,\n",
    "                                      update='replace')\n",
    "\n",
    "        return total_loss / (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3054e3d75051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'solver' is not defined"
     ]
    }
   ],
   "source": [
    "solver.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f_torch",
   "language": "python",
   "name": "f_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
